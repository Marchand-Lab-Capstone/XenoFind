{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9520596-d34a-4ad2-bdfa-34f83fbc0415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nworking_directory = '/home/sebastian/Documents/GitHub/XenoFind/data/large_working_directory/'\\nworking_subdir = 'model_training/'\\njson_dir = working_directory + working_subdir + 'json_files/'\\njson_files = os.listdir(json_dir)\\n\\nlp = LineProfiler()\\nlp_wrapper = lp(fe.extract_batch_features)\\nlp_wrapper(json_dir+json_files[0], 100)\\nlp.print_stats()\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import feature_extraction as fe\n",
    "from line_profiler import LineProfiler\n",
    "import random\n",
    "\n",
    "'''\n",
    "working_directory = '/home/sebastian/Documents/GitHub/XenoFind/data/large_working_directory/'\n",
    "working_subdir = 'model_training/'\n",
    "json_dir = working_directory + working_subdir + 'json_files/'\n",
    "json_files = os.listdir(json_dir)\n",
    "\n",
    "lp = LineProfiler()\n",
    "lp_wrapper = lp(fe.extract_batch_features)\n",
    "lp_wrapper(json_dir+json_files[0], 100)\n",
    "lp.print_stats()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967cfb96-3855-40de-804a-8132368dbd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class PyTorchClassifier:\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 device,\n",
    "                 n_features,\n",
    "                 out_features,\n",
    "                 neurons,\n",
    "                 layers,\n",
    "                 activation_function,\n",
    "                 loss_function,\n",
    "                 n_epochs,\n",
    "                 learning_rate,\n",
    "                 random_state):\n",
    "        \n",
    "        self._param_string = (str(device) +', '+ str(n_features) +', '+ str(out_features) +', '+ str(neurons) +', '+ str(layers) +', '+ str(activation_function) +', '+str(loss_function)+', '+ str(n_epochs) +', '+ str(learning_rate) +', '+ str(random_state))\n",
    "        torch.manual_seed(random_state)\n",
    "        self.epochs = n_epochs\n",
    "        self.activation_function = activation_function\n",
    "        self.loss_function = loss_function\n",
    "        self.model = (self.ClassifierNetwork(input_features=n_features,output_features=out_features,neurons=neurons, layers=layers)).to(device)\n",
    "        self.optimizer = torch.optim.SGD(params = self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def train_model(self, features, classes):\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            self.model.train()\n",
    "            \n",
    "            class_logits = self.model(features)\n",
    "            \n",
    "            class_predictions = torch.softmax(class_logits, dim=1).argmax(dim=1)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return self.model\n",
    "    \n",
    "    def accuracy_score(self, y_true, y_pred):\n",
    "        valid = torch.eq(y_true, y_pred).sum()\n",
    "        acc = (valid/len(y_pred))\n",
    "        return acc\n",
    "    \n",
    "    def test_model(self, features, classes):\n",
    "        \n",
    "        test_logits = self.model(features)\n",
    "        \n",
    "        test_predictions = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "        test_loss = self.loss_function(test_logits,\n",
    "                                       classes)\n",
    "        \n",
    "        test_acc = self.accuracy_score(classes,\n",
    "                                       test_predictions)\n",
    "        \n",
    "        return (test_loss.item(), test_acc)\n",
    "        \n",
    "    class ClassifierNetwork(nn.Module):\n",
    "        def __init__(self, input_Features, output_features, neurons, layers):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.linear_layer_stack = nn.Sequential()\n",
    "            self.linear_layer_stack.append(nn.linear(in_features = input_features, out_Features = neurons))\n",
    "            \n",
    "            for i in range(layers-1):\n",
    "                \n",
    "                self.linear_layer_stack.append(self.activation_function)\n",
    "                \n",
    "                if (i == (layers-2)):\n",
    "                    self.linear_layer_stack.append(nn.Linear(in_features=neurons, out_features = output_features))\n",
    "                else:\n",
    "                    self.linear_layer_stack.append(nn.Linear(in_features=neurons, out_Features = neurons))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.linear_layer_stack(x)\n",
    "    def __str__(self):\n",
    "        return self._param_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee5623c3-c813-49db-8005-17a6fe9a5ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert training data to tensors\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m tr_x_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mx_tr\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m tr_y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_tr)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convert testing data to tensors\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_tr' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up device for pytorch\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# Convert training data to tensors\n",
    "tr_x_tensor = torch.tensor(x_tr.values).type(torch.float).to(device)\n",
    "tr_y_tensor = torch.tensor(y_tr).type(torch.LongTensor).to(device)\n",
    "\n",
    "# Convert testing data to tensors\n",
    "te_x_tensor = torch.tensor(x_te.values).type(torch.float).to(device)\n",
    "te_y_tensor = torch.tensor(y_te).type(torch.LongTensor).to(device)\n",
    "\n",
    "# number of features\n",
    "feature_num = tr_x_tensor.shape[1]\n",
    "\n",
    "out_features = 2\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "l_rate = .1\n",
    "\n",
    "rs=42\n",
    "\n",
    "neurons=10\n",
    "layers = 3\n",
    "\n",
    "loss_fxn = nn.CrossEntropyLoss()\n",
    "actv_fxn = nn.ReLU()\n",
    "\n",
    "PTmodel = PyTorchClassifier(device=device,\n",
    "                            n_features = feature_num,\n",
    "                            out_features = out_features,\n",
    "                            neurons = neurons,\n",
    "                            layers = layers,\n",
    "                            activation_function = actv_fxn,\n",
    "                            loss_function = loss_fxn,\n",
    "                            n_epotchs=epochs,\n",
    "                            learning_rate=l_rate,\n",
    "                            random_state=rs)\n",
    "\n",
    "PTmodel.train_model(tr_x_tensor, tr_y_tensor)\n",
    "train_loss, train_acc = PTmodel.test_model(tr_x_tensor, tr_y_tensor)\n",
    "test_loss, test_acc = PTmodel.test_model(te_x_tensor, te_y_tensor)\n",
    "\n",
    "print(\"Training: {}, Testing: {}\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093278b1-1e88-4fed-9496-9a0b10d298d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xna_seq",
   "language": "python",
   "name": "xna_seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
