{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87192773-1d80-4425-8ce6-132728e7509c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..//')\n",
    "sys.path.append('lib/model_gen/')\n",
    "\n",
    "import merge_consensus as mc\n",
    "import pod5\n",
    "#import tracemalloc\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import multiprocessing\n",
    "#tracemalloc.start()\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe3259-1ab1-4b9e-a64d-380311f37523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod5_str = \"../../data/large_working_directory/merged_pod5/merged.pod5\"\n",
    "bam_str = \"../../data/large_working_directory/rough_consensus_output/large_align.bam\"\n",
    "fasta_str = \"../../data/reads_large/230725_PZ_lib_v4_r10/fasta/good.fa\"\n",
    "\n",
    "loading_pool = multiprocessing.Pool(processes=4)\n",
    "merged_data = loading_pool.starmap(mc.merge_bam_reads_by_id, [(loading_pool.map(mc.load_pod5_data, [pod5_str])[0],\n",
    "                                                               loading_pool.map(mc.load_in_data, [bam_str])[0],\n",
    "                                                               loading_pool.map(mc.consensus_formatter, [fasta_str])[0])])\n",
    "loading_pool.close()\n",
    "loading_pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfa701-a43b-4be5-8483-b02181f6ef0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod5 load called...\n"
     ]
    }
   ],
   "source": [
    "pod5_str = \"../../data/large_working_directory/merged_pod5/merged.pod5\"\n",
    "p5i.load_pod5_data(pod5_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780dee3-21d3-4cb1-8284-3bd508e7748a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod5\n"
     ]
    }
   ],
   "source": [
    "pod5_str = \"../../data/large_working_directory/merged_pod5/merged.pod5\"\n",
    "bam_str = \"../../data/large_working_directory/rough_consensus_output/large_align.bam\"\n",
    "fasta_str = \"../../data/reads_large/230725_PZ_lib_v4_r10/fasta/good.fa\"\n",
    "\n",
    "loading_pool = multiprocessing.Pool(processes=4)\n",
    "merged_data = loading_pool.starmap(mc.merge_bam_reads_by_id, [(loading_pool.map(mc.load_pod5_data, [pod5_str])[0],\n",
    "                                                               loading_pool.map(mc.load_in_data, [bam_str])[0],\n",
    "                                                               loading_pool.map(mc.consensus_formatter, [fasta_str])[0])])\n",
    "loading_pool.close()\n",
    "loading_pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d6bdaf-4a54-4725-9b2f-c1c7306f80b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>signal</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0036175b-fc7a-4f57-9c34-5bf6f4862c6a</td>\n",
       "      <td>[106.97853, 118.42194, 119.46225, 118.94209, 1...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>009e4f6d-f975-4642-8349-e033500d8018</td>\n",
       "      <td>[118.59533, 119.80902, 119.288864, 119.80902, ...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ed1d8c-35f1-4fbf-9d0c-77ad74d3428c</td>\n",
       "      <td>[96.57543, 109.05915, 105.76484, 99.17621, 108...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01057a9b-f69d-4acf-8cf6-e376b48504d0</td>\n",
       "      <td>[124.83719, 124.31703, 119.98241, 118.94209, 1...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01487f03-cb51-43ed-b3ec-03001dc0562a</td>\n",
       "      <td>[129.69197, 117.03486, 119.288864, 117.03486, ...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403518</th>\n",
       "      <td>feccb522-b866-4b7b-a37e-1ae119759e72</td>\n",
       "      <td>[118.24856, 124.83719, 123.27672, 114.260704, ...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403519</th>\n",
       "      <td>ff900236-f0d0-47f1-b6ca-8730f73c3934</td>\n",
       "      <td>[110.099464, 106.63176, 121.54287, 122.23641, ...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403520</th>\n",
       "      <td>ffcfd044-b23f-49ac-a4ea-dbc9d33b39e3</td>\n",
       "      <td>[160.90126, 119.635635, 120.15579, 119.98241, ...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403521</th>\n",
       "      <td>ffea84b4-197c-4eef-8cee-eebde83579c7</td>\n",
       "      <td>[114.43409, 113.047005, 112.180084, 109.75269,...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403522</th>\n",
       "      <td>fffa660f-dfb8-480d-b2ca-580862f707af</td>\n",
       "      <td>[105.0713, 119.635635, 119.98241, 118.76871, 1...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403523 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      seq_id  \\\n",
       "0       0036175b-fc7a-4f57-9c34-5bf6f4862c6a   \n",
       "1       009e4f6d-f975-4642-8349-e033500d8018   \n",
       "2       00ed1d8c-35f1-4fbf-9d0c-77ad74d3428c   \n",
       "3       01057a9b-f69d-4acf-8cf6-e376b48504d0   \n",
       "4       01487f03-cb51-43ed-b3ec-03001dc0562a   \n",
       "...                                      ...   \n",
       "403518  feccb522-b866-4b7b-a37e-1ae119759e72   \n",
       "403519  ff900236-f0d0-47f1-b6ca-8730f73c3934   \n",
       "403520  ffcfd044-b23f-49ac-a4ea-dbc9d33b39e3   \n",
       "403521  ffea84b4-197c-4eef-8cee-eebde83579c7   \n",
       "403522  fffa660f-dfb8-480d-b2ca-580862f707af   \n",
       "\n",
       "                                                   signal  freq  \n",
       "0       [106.97853, 118.42194, 119.46225, 118.94209, 1...  4000  \n",
       "1       [118.59533, 119.80902, 119.288864, 119.80902, ...  4000  \n",
       "2       [96.57543, 109.05915, 105.76484, 99.17621, 108...  4000  \n",
       "3       [124.83719, 124.31703, 119.98241, 118.94209, 1...  4000  \n",
       "4       [129.69197, 117.03486, 119.288864, 117.03486, ...  4000  \n",
       "...                                                   ...   ...  \n",
       "403518  [118.24856, 124.83719, 123.27672, 114.260704, ...  4000  \n",
       "403519  [110.099464, 106.63176, 121.54287, 122.23641, ...  4000  \n",
       "403520  [160.90126, 119.635635, 120.15579, 119.98241, ...  4000  \n",
       "403521  [114.43409, 113.047005, 112.180084, 109.75269,...  4000  \n",
       "403522  [105.0713, 119.635635, 119.98241, 118.76871, 1...  4000  \n",
       "\n",
       "[403523 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod5_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326e6187-63de-419d-bda1-3ed8b669e183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Memory Report 2024-05-14 13:56:56.518338 ]------------------------------------------------\n",
      "RSS: 4.734124032 gb, VMS: 8.298565632 gb, SHARED: 0.013238272 gb, DATA: 6.079442944 gb\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "memory_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abddd4ff-ec3a-4c8c-bd12-c5e1f4e19c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unbatched = ['a','b','c','d']\n",
    "n=3\n",
    "batched = [unbatched[i:i+n] for i in range(0, len(unbatched), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b183ac-9551-42e1-9a55-8ffc20300ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reads = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a886c9-aff9-466a-bf64-cc0fee5e5639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c'], ['d']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa96fb70-ac79-4021-8e26-2c547d4060ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_by_consensus(merged_signal_list_dict, savefile_path):\n",
    "    '''\n",
    "    save_by_consensus() saves reads by consensus in their own individual json files.\n",
    "    \n",
    "    Parameters:\n",
    "    merged_signal_list_dict: list of dicts containing relevant data keys: [ref_name,\n",
    "                                                               quality,\n",
    "                                                               len,\n",
    "                                                               ref,\n",
    "                                                               rev,\n",
    "                                                               moves,\n",
    "                                                               sig_len,\n",
    "                                                               trim_offs,\n",
    "                                                               freq,\n",
    "                                                               ref_seq]\n",
    "    savefile_path: folder that the json files will be exported to, as a str. MAKE SURE IT ENDS WITH '/'.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(merged_signal_list_dict)\n",
    "    \n",
    "    os.makedirs(savefile_path, exist_ok=True)\n",
    "\n",
    "    consensus_ids = list(df['ref_name'].unique())\n",
    "    \n",
    "    n=3\n",
    "    batched_consensuses = [consensus_ids[i:i+n] for i in range(0, len(consensus_ids), n)]\n",
    "    \n",
    "    \n",
    "    with alive_bar(len(consensus_ids)) as bar:\n",
    "        \n",
    "        for batch in batched_consensuses:\n",
    "            \n",
    "            pool = multiprocessing.Pool(processes = n)\n",
    "            pre_assign = functools.partial(save_to_json, df)\n",
    "            pool.map(pre_assign, batch)\n",
    "            pool.close()\n",
    "            for i in range(n):\n",
    "                bar()\n",
    "        \n",
    "def save_to_json(consensus_id,df):\n",
    "    consensus = df[df['ref_name'] == consensus_id]\n",
    "\n",
    "    # Condense the data types (Making sure no info is lost)\n",
    "    consensus.loc[:,'quality']=consensus['quality'].apply(np.int16)\n",
    "    consensus.loc[:,'len']=consensus['len'].apply(np.int16)\n",
    "    consensus.loc[:,'ref']=consensus['ref'].apply(np.int16)\n",
    "    consensus.loc[:,'rev']=consensus['rev'].apply(np.int16)\n",
    "    consensus.loc[:,'moves']=consensus['moves'].apply(np.asarray)\n",
    "    consensus.loc[:,'sig_len']=consensus['sig_len'].apply(np.int16)\n",
    "    consensus.loc[:,'trim_ofs']=consensus['trim_ofs'].apply(np.int16)\n",
    "    consensus = consensus.reset_index(drop=True)\n",
    "    # sub method to convert datatypes in a list to a list\n",
    "\n",
    "    def listconvert(x):\n",
    "        # submethod listconvert is used to map subsects of data entries to lists.\n",
    "        for i in range(len(x)):\n",
    "            x[i]=list(x[i])\n",
    "        return x\n",
    "\n",
    "    consensus.loc[:,'signal']=consensus['signal'].apply(listconvert)\n",
    "    consensus.loc[:,'freq']=consensus['freq'].apply(np.float16)\n",
    "\n",
    "    # Get the reference name, sequence, and frequency - \n",
    "    # #### THIS IS ASSUMING THAT THE FREQUENCY IS THE SAME FOR ALL READS ####\n",
    "    ref_name = consensus['ref_name'][0]\n",
    "    ref_seq = consensus['ref_seq'][0]\n",
    "    freq = consensus['freq'][0]\n",
    "\n",
    "    # generate the header and filename\n",
    "    header = {'ref_seq':ref_seq,'freq':freq}\n",
    "    filename = \"cons_merge__{}.json\".format(ref_name)\n",
    "\n",
    "    # generate the filepath\n",
    "    filepath = savefile_path + filename\n",
    "\n",
    "    # generate the json object with the header and the dataframe\n",
    "    json_frame = consensus.to_json() # conver dataframe to json\n",
    "    json_frame = json.loads(json_frame) # convert json back to dict\n",
    "    json_out = json.dumps([header, json_frame]) # convert list of dicts to json\n",
    "\n",
    "    # if the path exists, overwrite it\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "\n",
    "    # write the json object\n",
    "    with open(filepath, 'a') as file:\n",
    "        file.write(json_out)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a71a2083-738a-42fd-8ebf-f9317b941478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import functools\n",
    "\n",
    "def f(x, a):\n",
    "    return(x*a)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(processes=30)\n",
    "    prod_x = functools.partial(f, a=10)\n",
    "    pool.map(prod_x, np.arange(0, 30, 1))\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376fc281-11cc-4c50-8209-675efb409998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function f at 0x76819cc7e9d0>, a=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4e6b800-ada7-4d00-b12e-77d1a61a789b",
   "metadata": {
    "tags": []
   },
   "source": [
    "bam_str = \"../../data/large_working_directory/rough_consensus_output/large_align.bam\"\n",
    "bam = mc.load_in_data(bam_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f677b-51df-4a9c-aa7f-0915cc762056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pd.DataFrame(bam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba8a3b5-1997-42d7-b617-f67c0db4308a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasta_str = \"../../data/reads_large/230725_PZ_lib_v4_r10/fasta/good.fa\"\n",
    "fasta = mc.consensus_formatter(fasta_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d88a63-645b-4ad0-96f9-d3f581ff45c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0685730-4724-42e3-8dee-0a67c7e212ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'lib_pod5.pod5_format_pybind.Pod5FileReader' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reads \u001b[38;5;241m=\u001b[39m \u001b[43mp5i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pod5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpod5_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/XenoFind/lib/xf_prelims/pod5_importer.py:37\u001b[0m, in \u001b[0;36mload_pod5_data\u001b[0;34m(p5_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batched_reads:\n\u001b[1;32m     36\u001b[0m     pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes \u001b[38;5;241m=\u001b[39m n)\n\u001b[0;32m---> 37\u001b[0m     data_list\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m     pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     40\u001b[0m pod5_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/pool.py:537\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/connection.py:206\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'lib_pod5.pod5_format_pybind.Pod5FileReader' object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab3bb3dd-8c24-4669-9c58-573585ff6a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def invoke_pod5_importer(path):\n",
    "    output = subprocess.run([\"python\", \"pod5_importer.py\", \"{}\".format(path)])\n",
    "    print(output)\n",
    "    return output.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddcfef69-526e-4f15-996e-81ce7f4102d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['python', 'pod5_importer.py', '../../data/large_working_directory/merged_pod5/merged.pod5'], returncode=1)\n"
     ]
    }
   ],
   "source": [
    "pod5_df = invoke_pod5_importer(pod5_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c24326-3726-40f6-a983-47ce9effaf41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pandas/io/pickle.py:196\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    195\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pandas/io/pickle.py:196\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;66;03m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf2cca3-1325-4b67-b932-3a0de292f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "usage: pod5_importer.py [-h] path\n",
      "\n",
      "pod5 loading\n",
      "\n",
      "positional arguments:\n",
      "  path        Path to Pod5 file.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help  show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "!python pod5_importer.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2c3dbd-83bb-4b67-86c6-c5e0e53a3585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def memory_report():\n",
    "    #snapshot = tracemalloc.take_snapshot()\n",
    "    #top_stats = snapshot.statistics('lineno')\n",
    "    proc = psutil.Process(os.getpid())\n",
    "    rss = proc.memory_info().rss/(1*10**9)\n",
    "    vms= proc.memory_info().vms/(1*10**9)\n",
    "    shared = proc.memory_info().shared/(1*10**9)\n",
    "    data = proc.memory_info().data/(1*10**9)\n",
    "    #size,peak= tracemalloc.get_traced_memory()\n",
    "    print(\"[ Memory Report {} ]------------------------------------------------\".format(datetime.datetime.now()))\n",
    "    print(\"RSS: {} gb, VMS: {} gb, SHARED: {} gb, DATA: {} gb\".format(rss, vms, shared, data))\n",
    "    #print(\"Size: {} gb, Peak {} gb\".format(size/(1*10**9),peak/(1*10**9)))\n",
    "    #print(\"[ Top 5 Memory Uses ]\")\n",
    "    #for stat in top_stats[:5]:\n",
    "    #    print(stat)\n",
    "    print(\"--------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20df17d8-f036-4814-88bc-205010249beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Memory Report 2024-05-13 17:38:04.667684 ]------------------------------------------------\n",
      "RSS: 0.190906368 gb, VMS: 3.750793216 gb, SHARED: 0.07929856 gb, DATA: 1.68767488 gb\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "memory_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04b10eb-0331-4920-b314-e04a036e1b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(mc.load_pod5_data(pod5_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16989855-cf84-4396-af78-5e82e31e3f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testt():\n",
    "    memory_report()\n",
    "    df2 = pd.read_pickle('export_merge_pod5.pickle')\n",
    "    print(sys.getsizeof(df2))\n",
    "    memory_report()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913007a7-bfe3-407b-aa2a-4e552f53a852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Memory Report 2024-05-13 17:38:07.978003 ]------------------------------------------------\n",
      "RSS: 0.190906368 gb, VMS: 3.750793216 gb, SHARED: 0.07929856 gb, DATA: 1.68767488 gb\n",
      "--------------------------------------------------------------------------------------------\n",
      "89178727\n",
      "[ Memory Report 2024-05-13 17:38:12.617379 ]------------------------------------------------\n",
      "RSS: 8.398368768 gb, VMS: 11.957264384 gb, SHARED: 0.080216064 gb, DATA: 9.894146048 gb\n",
      "--------------------------------------------------------------------------------------------\n",
      "[ Memory Report 2024-05-13 17:38:12.876167 ]------------------------------------------------\n",
      "RSS: 4.825284608 gb, VMS: 8.383905792 gb, SHARED: 0.080347136 gb, DATA: 6.320787456 gb\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "testt()\n",
    "memory_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424e3fbb-6656-45e6-a459-4e747f0562fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498283, 8168251563)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size,peak= tracemalloc.get_traced_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40f450-5330-4487-b399-2fcff56ff42f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7833c742-d3c6-47b5-9560-43ffc5c37385",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fd54f8-7ae6-447a-9cc1-5aea9270a907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tryscale(scale):\n",
    "    print(scale)\n",
    "    data_list = []\n",
    "    for i in range(1):\n",
    "        data_list = []\n",
    "        with pod5.Reader(pod5_str) as pod5_file:\n",
    "            memory_report()\n",
    "            reads=list(pod5_file.reads())\n",
    "\n",
    "            for i in range(len(reads[:scale])):\n",
    "                read = reads[i]\n",
    "                # save the sequence id, signal, and frequency to a dict\n",
    "                data_dict = getreaddict(read)\n",
    "                # append the dict to the list\n",
    "                data_list.append(data_dict)\n",
    "            pod5_file.close()\n",
    "            memory_report()\n",
    "        memory_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18dc105-f52c-413d-976f-ebbb1096cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getreaddict(read):        \n",
    "    return data_dict\n",
    "    seq_id = read.read_id\n",
    "    signal = read.signal_pa\n",
    "    freq = read.run_info.sample_rate\n",
    "    data_dict = {'seq_id': str(seq_id),\n",
    "                 'signal': signal,\n",
    "                 'freq': freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c08b8a-7e49-4416-be2c-2525cc943cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[dataframe] in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (2023.5.0)\n",
      "Requirement already satisfied: click>=8.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (7.0.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.3 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from dask[dataframe]) (2.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from pandas>=1.3->dask[dataframe]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from pandas>=1.3->dask[dataframe]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from pandas>=1.3->dask[dataframe]) (2024.1)\n",
      "Requirement already satisfied: locket in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from partd>=1.2.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.3->dask[dataframe]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"dask[dataframe]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a6310-b7e8-469a-8793-c984aa274369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e882ca-757b-474c-baf3-a67147f89110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Top 5 Memory Uses ]--------------------------\n",
      "/home/sebastian/.conda/envs/xna_seq/lib/python3.8/tracemalloc.py:65: size=18.7 KiB, count=299, average=64 B\n",
      "/home/sebastian/.conda/envs/xna_seq/lib/python3.8/tracemalloc.py:532: size=15.5 KiB, count=325, average=49 B\n",
      "/home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:106: size=13.3 KiB, count=81, average=168 B\n",
      "/home/sebastian/.conda/envs/xna_seq/lib/python3.8/site-packages/IPython/core/builtin_trap.py:70: size=9248 B, count=1, average=9248 B\n",
      "/home/sebastian/.conda/envs/xna_seq/lib/python3.8/abc.py:102: size=9217 B, count=95, average=97 B\n"
     ]
    }
   ],
   "source": [
    "memory_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c4a0ffe-f4ce-4001-8531-ce23d8a0231b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ArrowTableHandle has been closed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m read \u001b[38;5;129;01min\u001b[39;00m reads_list:\n\u001b[1;32m      3\u001b[0m     seq_id \u001b[38;5;241m=\u001b[39m read\u001b[38;5;241m.\u001b[39mread_id\n\u001b[0;32m----> 4\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_pa\u001b[49m\n\u001b[1;32m      5\u001b[0m     freq \u001b[38;5;241m=\u001b[39m read\u001b[38;5;241m.\u001b[39mrun_info\u001b[38;5;241m.\u001b[39msample_rate\n\u001b[1;32m      6\u001b[0m     data_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(seq_id),\n\u001b[1;32m      7\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m: signal,\n\u001b[1;32m      8\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m'\u001b[39m: freq}\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:320\u001b[0m, in \u001b[0;36mReadRecord.signal_pa\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignal_pa\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mfloat32]:\n\u001b[1;32m    312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Get the full signal for the read, calibrated in pico amps.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m        A numpy array of signal data in pico amps with float32 type.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalibrate_signal_array(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:287\u001b[0m, in \u001b[0;36mReadRecord.signal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_signal_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_row]\n\u001b[1;32m    286\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39msignal[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_row]\n\u001b[0;32m--> 287\u001b[0m batch_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_signal_row_index(r\u001b[38;5;241m.\u001b[39mas_py()) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rows]\n\u001b[1;32m    288\u001b[0m sample_counts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, _, batch_row_index \u001b[38;5;129;01min\u001b[39;00m batch_data:\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:287\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_signal_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_row]\n\u001b[1;32m    286\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39msignal[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_row]\n\u001b[0;32m--> 287\u001b[0m batch_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_signal_row_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rows]\n\u001b[1;32m    288\u001b[0m sample_counts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, _, batch_row_index \u001b[38;5;129;01min\u001b[39;00m batch_data:\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:381\u001b[0m, in \u001b[0;36mReadRecord._find_signal_row_index\u001b[0;34m(self, signal_row)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_signal_row_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, signal_row: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Signal, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Map from a signal_row to a Signal, batch index and row index within that batch.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    A Tuple containing the `Signal` and its `batch_index` and `row_index`\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     sig_row_count: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_batch_row_count\u001b[49m\n\u001b[1;32m    382\u001b[0m     sig_batch_idx: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m signal_row \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m sig_row_count\n\u001b[1;32m    383\u001b[0m     sig_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39m_get_signal_batch(sig_batch_idx)\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:808\u001b[0m, in \u001b[0;36mReader.signal_batch_row_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return signal batch row count\"\"\"\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_batch_row_count \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_table\u001b[49m\u001b[38;5;241m.\u001b[39mnum_record_batches \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_batch_row_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_table\u001b[38;5;241m.\u001b[39mget_batch(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/pod5/reader.py:772\u001b[0m, in \u001b[0;36mReader.signal_table\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Access the pod5 signal table - use with caution\"\"\"\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrowTableHandle has been closed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_handle\u001b[38;5;241m.\u001b[39mreader\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ArrowTableHandle has been closed!"
     ]
    }
   ],
   "source": [
    "read_list_dict = []\n",
    "for read in reads_list:\n",
    "    seq_id = read.read_id\n",
    "    signal = read.signal_pa\n",
    "    freq = read.run_info.sample_rate\n",
    "    data_dict = {'seq_id': str(seq_id),\n",
    "                 'signal': signal,\n",
    "                 'freq': freq}\n",
    "    read_list_dict.append(data_dict)\n",
    "memory_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005685a7-04a6-4ce8-bec8-986706382cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
