{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00c7107-017d-4a16-84d3-fa1b80379529",
   "metadata": {},
   "source": [
    "# Training Walkthrough\n",
    "Sebastian Peck, June 4th 2024\n",
    "\n",
    "This is a notebook-level walthrough of the training process for our current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa748ae2-d725-400e-bec1-4f8612e1460b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, we import all the relevant packages:\n",
    "# Base packages for data processing and cleanliness\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# adjust the path to include the directory for our own python files\n",
    "sys.path.append('..//..//model_gen')\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4cb7f40-7711-4644-9cd8-15b0a5a3b507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Then,the machine learning packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# and setup the device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83298af3-84a2-4000-8067-815411af7f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up the operational directories\n",
    "\n",
    "# working directory, reference fasta, etc. The stuff typically handled by the pipeline\n",
    "working_directory = '/media/sebastian/Slepnir/xenofind_datasets/Working_directory_PZ/'\n",
    "ref_fasta = \"/media/sebastian/Slepnir/xenofind_datasets/xref_libv2_PZ_CxDx.fa\"\n",
    "working_subdir=''\n",
    "fasta_path = ''\n",
    "IS_TRAINING = True\n",
    "GLOBAL_RANDOM_STATE = 0\n",
    "window_size = 3\n",
    "\n",
    "# set up the random seed\n",
    "random.seed(0)\n",
    "\n",
    "if IS_TRAINING:\n",
    "    fasta_path = ref_fasta\n",
    "    working_subdir = 'model_training/'\n",
    "else:\n",
    "    working_subdir = 'model_testing/'\n",
    "    fasta_path = working_directory + working_subdir + 'consensus.fa'\n",
    "    \n",
    "bam_path = working_directory + working_subdir + 'basecall_directory/fwd_filtered.bam'\n",
    "pod5_path = working_directory + working_subdir + 'merged_pod5/merged.pod5'\n",
    "json_dir = working_directory + working_subdir + 'json_files/'\n",
    "parquet_dir = working_directory + working_subdir + 'parquet_superdirectory/'\n",
    "singlet_consensus_dir = working_directory + working_subdir + \"json_feature_files/\"\n",
    "model_dir = working_directory + working_subdir + 'Models/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db7915-ff3a-47de-a9f4-d7c14af4e3be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Custom Methods for modeling:\n",
    "percenttobar - takes a fraction and converts it to a loading bar string \n",
    "\n",
    "\n",
    "find_pca_components - generates a list of explained variance as percent for each number of components \n",
    "\n",
    "\n",
    "PyTorchClassifier - A custom sklearn-styled classifyer for generating a variable pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5f2263-6941-4548-a020-779121e6823c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def percenttobar(frac):\n",
    "    bar_str = \"|\"\n",
    "    max_bars = 20\n",
    "    perc = frac*2000\n",
    "    n_bars = int(perc/100)\n",
    "    for i in range(n_bars):\n",
    "        bar_str += \"=\"\n",
    "    for i in range(max_bars-n_bars):\n",
    "        bar_str += \" \"\n",
    "    bar_str += \"|  {}%                \".format(round(frac*100, 3))\n",
    "    return bar_str\n",
    "    \n",
    "def find_pca_components(comp_list, data):\n",
    "    '''\n",
    "    find_pca_components takes in a list of number of components to be used,\n",
    "    as well as feature data to be used for PCA, and returns the\n",
    "    list of total explained variance as a percent for each number of components.\n",
    "    \n",
    "    Parameters:\n",
    "    comp_list: List of ints representing number of components of interest\n",
    "    data: pandas dataframe containing scaled unit variance feature data\n",
    "    \n",
    "    Returns:\n",
    "    a list of explained variance as a percent for each number of components\n",
    "    '''\n",
    "    \n",
    "    # Set up empty list\n",
    "    explained = []\n",
    "    # Loop through all components in the list\n",
    "    for components in comp_list:\n",
    "        # Set up PCA with the number of components of interest and the global random\n",
    "        pca = PCA(n_components=components, random_state = GLOBAL_RANDOM_STATE)\n",
    "        # Fit the data\n",
    "        pca.fit(data)\n",
    "        # Get the total explained variance ratio\n",
    "        pcen_expl = (pca.explained_variance_ratio_).sum()\n",
    "        # Add the value to the empty list\n",
    "        explained.append(pcen_expl)\n",
    "        \n",
    "    # return the explained list\n",
    "    return explained\n",
    "\n",
    "class PyTorchClassifier:\n",
    "    '''\n",
    "    Originally written by S. Peck and A. Mahmoud, Adapted for this project by S. Peck, and is licensed for this sole implementation. \n",
    "    \n",
    "    PyTorchClassifier - Sebastian Peck, 12/1/2023\n",
    "    PyTorchClassifier is an sklearn-styled class to aid in\n",
    "    the classification of data using a pytorch neural network.\n",
    "    Initialization requires the device to run pytorch on,\n",
    "    number of input features, and number of classes.\n",
    "    \n",
    "    Updated 6/4/2024 - S. Peck\n",
    "    UPDATED 6/5/2024 - S. PECK\n",
    "    \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 device,\n",
    "                 n_features:int,\n",
    "                 out_features:int,\n",
    "                 nl_list:list=[5, 5, 5],\n",
    "                 activation_function=nn.ReLU(),\n",
    "                 loss_function=nn.CrossEntropyLoss(),\n",
    "                 n_epochs:int=1000,\n",
    "                 learning_rate:float=.1,\n",
    "                 random_state:int=42,\n",
    "                 class_weights:list=[0]):\n",
    "        '''\n",
    "        initializing PyTorchClassifyer sets pytoch's random\n",
    "        seed and generates the loss function, optimizer,\n",
    "        and model of neural network based on passed parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        device: the device running pytorch\n",
    "        n_features: number of features in data as int\n",
    "        out_features: number of classes in the data as int\n",
    "        nl_list: a list, with number of indexes as layers, \n",
    "                 and values representing neurons at that layer(as ints) Default = [5, 5, 5]\n",
    "        activation_function: the torch.nn activation function of choice. Default = ReLU()\n",
    "        loss_function: the torch.nn loss function of choice. Defualt = CrossEntropyLoss()\n",
    "        n_epochs: int of number of epochs to perform when training. Default= 1000\n",
    "        learning_rate: float representing learning rate. Defualt = .1\n",
    "        random_state: the random state to use. Default = 42\n",
    "        class_weights: List of class weights USED FOR BOOKKEEPING AND DOES NOT ACTUALLY PASS TO LOSS FXN.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        # Generate a string of the parameters\n",
    "        self._param_string = (str(device) +'|'+ str(n_features) +'|'+ str(out_features) +'|'+ str(nl_list) +'|'+ str(activation_function) +'|'+str(loss_function)+'|'+ str(n_epochs) +'|'+ str(learning_rate) +'|'+ str(random_state) + '|' + str(class_weights))\n",
    "        \n",
    "        # assign the random seed to pytorch\n",
    "        torch.manual_seed(random_state)\n",
    "        \n",
    "        # set the class variables\n",
    "        self.epochs = n_epochs\n",
    "        self.activation_function = activation_function\n",
    "        self.loss_function = loss_function\n",
    "        self.device = device\n",
    "        self.n_features = n_features\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Generate the model using the local ClassifierNetwork class\n",
    "        self.model = (self.ClassifierNetwork(input_features=n_features,output_features=out_features,nl_list = nl_list, activation_function = self.activation_function)).to(device)\n",
    "        \n",
    "        # Optimize the model using SGD\n",
    "        self.optimizer = torch.optim.SGD(params = self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "\n",
    "    \n",
    "    def train_model(self, dataloader, epochs=None):\n",
    "        if type(epochs) == type(None):epochs=self.epochs\n",
    "        '''\n",
    "        train_model takes in a torch formatted dataset of features,\n",
    "        and the corresponding torch formatted dataset of classes,\n",
    "        and trains the current model version on that data.\n",
    "        \n",
    "        Parameters:\n",
    "        dataloader: a TensorDataset DataLoader object containing the data to be processed.\n",
    "        epochs: an int representing number of epochs to train this dataset. Default is the passed epochs when creating the model.\n",
    "        \n",
    "        Returns:\n",
    "        The trained model.\n",
    "        '''\n",
    "        \n",
    "        # Set up the model to train\n",
    "        self.model.train()\n",
    "        \n",
    "        # repeat for every epoch\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            \n",
    "            # load a subset from the dataloader\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                \n",
    "                # generate the features and classes\n",
    "                features, classes = x.to(self.device), y.to(self.device)\n",
    "\n",
    "                # Forward Pass - pass the features and\n",
    "                # convert to class logits\n",
    "                class_logits = self.model(features)\n",
    "\n",
    "                # Convert the logits to probabilities to labels using softmax\n",
    "                class_predictions = torch.softmax(class_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "                # Calculate loss\n",
    "                # passing the logits and the training classes\n",
    "                loss = self.loss_function(class_logits, classes)\n",
    "\n",
    "                # Reset the optimizer gradient\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # set backwards loss training\n",
    "                loss.backward()\n",
    "\n",
    "                # step the optimizer by one\n",
    "                self.optimizer.step()\n",
    "            print(\"{}  {}/{}         \".format(percenttobar(epoch/epochs), epoch, epochs), end=\"\\r\")\n",
    "            \n",
    "        # return the model\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "    def save_model_state(self, path, filename):\n",
    "        '''\n",
    "        save_model saves the model state to the given path.\n",
    "        \n",
    "        Parameters:\n",
    "        path: path, as str, to the save location directory, must end with '/'\n",
    "        filename: name of the file to be saved, as str\n",
    "        \n",
    "        Returns:\n",
    "        path to saved file, as str\n",
    "        '''\n",
    "        \n",
    "        # generate savefile strings for the state and parameters\n",
    "        save_path_str = '{}{}/state.pt'.format(path, filename)\n",
    "        save_path_str_2 = '{}{}/params.txt'.format(path, filename)\n",
    "        \n",
    "        if not os.path.isfile('{}{}'.format(path, filename)):\n",
    "            os.mkdir('{}{}'.format(path, filename))\n",
    "        \n",
    "        # save the state\n",
    "        torch.save(self.model.state_dict(), save_path_str)\n",
    "        \n",
    "        # save the parameters\n",
    "        with open(save_path_str_2, 'w') as f:\n",
    "            f.write(self._param_string)\n",
    "        \n",
    "        # return the directory\n",
    "        return save_path_str\n",
    "    \n",
    "    \n",
    "    def load_model_state(self, path):\n",
    "        '''\n",
    "        load_model_state loads the model state from a given path.\n",
    "        \n",
    "        Parameters:\n",
    "        path: Path, as str, to the saved parameters file\n",
    "        \n",
    "        Returns:\n",
    "        the loaded model, in evaluation state\n",
    "        '''\n",
    "        \n",
    "        # load the model from the path\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "\n",
    "        # set the model into evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # return the model\n",
    "        return self.model\n",
    "            \n",
    "    \n",
    "    def accuracy_score(self, y_true, y_pred):\n",
    "        '''\n",
    "        accuracy_score takes in two torch tensors of true and predicted values\n",
    "        and returns the accuracy as a percentage fraction.\n",
    "        \n",
    "        Parameters:\n",
    "        y_true: pytorch tensor of LongTensors representing classes of each point\n",
    "        y_pred: pytorch tesnor of Longtensors representing predicted classses of each point\n",
    "        \n",
    "        Returns:\n",
    "        the accuracy fraction\n",
    "        '''\n",
    "        \n",
    "        # get number of the true predicted values to get the valid ones using torch.eq()\n",
    "        valid = torch.eq(y_true, y_pred).sum().item()\n",
    "        \n",
    "        # Generate the precentage fraction\n",
    "        acc = (valid/len(y_pred))\n",
    "        \n",
    "        # return the accuracy\n",
    "        return acc\n",
    "    \n",
    "    \n",
    "    def test_model(self, features, classes):\n",
    "        '''\n",
    "        test_model takes in a set of features and corresponding classes to\n",
    "        test how the model performs with that dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        features: a pytorch tensor of floats representing the data for each feature\n",
    "        classes: a pytorch tensor of LongTensors representing the classes for each point\n",
    "        \n",
    "        Returns:\n",
    "        a touple containing the loss and the accuracy.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # generate the logit values from the model by passing the test features\n",
    "        test_logits = self.model(features)\n",
    "        \n",
    "        # generate the predictions using torch.softmax() and the test logits\n",
    "        test_predictions = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "        # Generate the loss using the class's loss function\n",
    "        test_loss = self.loss_function(test_logits,\n",
    "                                       classes)\n",
    "        \n",
    "        # Generate the accuracy score using the class accuracy score function\n",
    "        test_acc = self.accuracy_score(classes,\n",
    "                                       test_predictions)\n",
    "        \n",
    "        # Generate a string to hold the results for pretty-printing if needed\n",
    "        #results = \"Loss: {}, Accuracy Score: {}\".format(test_loss, test_acc)\n",
    "        #print(results)\n",
    "        \n",
    "        # return a touple of the loss value and the test accuracy.\n",
    "        return (test_loss.item(), test_acc)\n",
    "    \n",
    "        \n",
    "    class ClassifierNetwork(nn.Module):\n",
    "        '''\n",
    "        ClassifierNetwork is a subclass of the Pytorch nn.Module,\n",
    "        which is meant to be used as a classifier.\n",
    "        '''\n",
    "        def __init__(self,\n",
    "                     input_features:int,\n",
    "                     output_features:int,\n",
    "                     nl_list:list=[5, 5, 5],\n",
    "                     activation_function=nn.ReLU()):\n",
    "            '''\n",
    "            Extends nn.Module.\n",
    "            \n",
    "            initializer sets up the model stack in sequential order according to the passed parameters.\n",
    "            Uses linear layer stack of linear nn layers.\n",
    "            \n",
    "            Parameters:\n",
    "            input_features: an int representing the number of features in the dataset\n",
    "            output_features: an int representing the number of classes in the dataset\n",
    "            nl_list: list representing number of neurons per layer,\n",
    "                     with n indexes as the number of layers, Default = [5, 5, 5]\n",
    "            activation_function: activation function of choice between layers. Default=nn.ReLU()\n",
    "            \n",
    "            Returns:\n",
    "            N/A\n",
    "            '''\n",
    "            \n",
    "            # Initialize the superclass\n",
    "            super().__init__()\n",
    "            \n",
    "            # generate the starting neurons as the first index in the list\n",
    "            starting_neurons = nl_list[0]\n",
    "            \n",
    "            # set up a sequential stack\n",
    "            self.linear_layer_stack = nn.Sequential()\n",
    "            \n",
    "            # add the first layer where the input features is the first number of neurons, and the output features are the starting neurons\n",
    "            self.linear_layer_stack.append(nn.Linear(in_features = input_features, out_features = starting_neurons))\n",
    "            \n",
    "            \n",
    "            # loop through each layer of the nl_list.\n",
    "            for i in range(len(nl_list)-1):\n",
    "                # append the activation function to the linear layer stack\n",
    "                self.linear_layer_stack.append(activation_function)\n",
    "\n",
    "                # append a new layer where the input features is the current index in the nl_list, and the subsequent is the next.\n",
    "                self.linear_layer_stack.append(nn.Linear(in_features=nl_list[i], out_features = nl_list[i+1]))\n",
    "                \n",
    "            # add the output layer\n",
    "            self.linear_layer_stack.append(activation_function)\n",
    "            self.linear_layer_stack.append(nn.Linear(in_features=nl_list[-1], out_features = output_features))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            '''\n",
    "            forward takes in a set of features and applies it to the linear layer stack.\n",
    "            \n",
    "            Paramters:\n",
    "            x: set of features. \n",
    "            \n",
    "            Returns:\n",
    "            the linear layer stack with the passed features.\n",
    "            '''\n",
    "            return self.linear_layer_stack(x)\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        '''\n",
    "        export self as string.\n",
    "        '''\n",
    "        return self._param_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f848676-2270-4cce-a847-763bd2ff8c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yoink_features(json_file,json_dir, singlet_consensus_dir, extracted_features):\n",
    "    # THIS CODE IS PRESENTLY BAD AS IT REFERENCES GLOBAL item JSON_DIR\n",
    "    if \"{}.parquet\".format(json_file) not in extracted_features:\n",
    "        json_file_path = json_dir + json_file\n",
    "        fe.feature_extraction(json_file_path).to_parquet(singlet_consensus_dir+\"{}.parquet\".format(json_file))\n",
    "\n",
    "def json_to_singlets(json_dir, singlet_consensus_dir, batch_size=15):\n",
    "    # List the files in the json directory\n",
    "    json_files = os.listdir(json_dir)\n",
    "\n",
    "    # get the files in the extracted features directory\n",
    "    extracted_features = os.listdir(singlet_consensus_dir)\n",
    "\n",
    "    # generate an empty list for read features\n",
    "    feature_read_list = []\n",
    "\n",
    "    # get the last time \n",
    "    last_time = datetime.datetime.now()\n",
    "\n",
    "    # Get the batches of json files in the directory\n",
    "    batched_json = [json_files[i:i+batch_size] for i in range(0, len(json_files), batch_size)]\n",
    "\n",
    "        \n",
    "    # set up dummy to hold run duration      \n",
    "    dur = 0\n",
    "\n",
    "    # loop through each batch in the batched json files\n",
    "    for i in range(len(batched_json)):\n",
    "\n",
    "        # get the batch of json files\n",
    "        json_batch = batched_json[i]\n",
    "        \n",
    "        j = []\n",
    "        s = []\n",
    "        e = []\n",
    "        for item in json_batch:\n",
    "            j.append(json_dir)\n",
    "            s.append(singlet_consensus_dir)\n",
    "            e.append(extracted_features)\n",
    " \n",
    "        zip_batch = list(zip(json_batch, j, s, e))\n",
    "\n",
    "        # setup a multiprocessing pool matching the batch size\n",
    "        with multiprocessing.Pool(batch_size) as pool:\n",
    "\n",
    "            # run feature extraction on the json files in the pool using yoink_features\n",
    "            feature_read_list.extend(pool.starmap(yoink_features, zip_batch))\n",
    "\n",
    "        # Get the time estimate and duration\n",
    "        time = datetime.datetime.now()\n",
    "        dt = (time-last_time).total_seconds()\n",
    "        dur += dt\n",
    "        mean_time = dur/(i+1)\n",
    "        est_time = datetime.timedelta(seconds = mean_time*len(batched_json))\n",
    "        last_time=time\n",
    "\n",
    "        # print an update on progress\n",
    "        print(percenttobar(i*batch_size/len(json_files)) + \"{}/{}   est_time:{} | {}\".format(i*batch_size, len(json_files), est_time, datetime.timedelta(seconds=dur)),end='\\r')\n",
    "    print(percenttobar(1))\n",
    "\n",
    "    \n",
    "def get_features_from_singlets(singlet_consensus_dir):\n",
    "    '''\n",
    "    get_features_from_singlets takes in a singlet consensus directory,\n",
    "    and then returns a list of dataframes of each reference sequence's consensus features.\n",
    "    Parameters:\n",
    "    singlet_consensus_dir: directory to all singlet consensus feature parquet files\n",
    "    \n",
    "    Returns:\n",
    "    List of dataframes, with ecach index being a different reference sequence\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # get the extracted features in the directory\n",
    "    extracted_features = os.listdir(singlet_consensus_dir)\n",
    "    \n",
    "    # generate an empty list to contain the features\n",
    "    feature_read_list = []\n",
    "    \n",
    "    # loop through all the extracted feature files\n",
    "    for i in range(len(extracted_features)):\n",
    "        \n",
    "        # append the parquet file to the feature read list after reading it using pandas\n",
    "        feature_read_list.append(pd.read_parquet(singlet_consensus_dir+ extracted_features[i]))\n",
    "        \n",
    "        # print the progress\n",
    "        print(percenttobar(i/len(extracted_features)) + \"{}/{}     \".format(i, len(extracted_features)),end='\\r')\n",
    "    print(percenttobar(1))\n",
    "        \n",
    "    # return the features list\n",
    "    return feature_read_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522456c-32c9-45ef-a003-dd4812aa9494",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing the data\n",
    "The data can come in either as Json files or parquet files. If the files are Json files, they will need to have their features extracted. Likewise, if they are parquets, you need to know their batching. For this model, we are merging all reads per reference sequence ot one set of consensus features per reference, from existing parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792665f-1903-471b-aec6-e590970b32c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Json-To-Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8a628-9646-4466-aecc-c305cc0b668c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_to_singlets(json_dir, singlet_consensus_dir, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b21a7b3-d96d-4166-8390-0783bc5470bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|====================|  100%                   8191/8192     \n"
     ]
    }
   ],
   "source": [
    "feature_read_list = get_features_from_singlets(singlet_consensus_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71db00f6-4a2a-4233-9ab7-b1c85b599efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df= pd.concat(feature_read_list[10:])\n",
    "n_bases = len(raw_df['XNA_PRESENT'])\n",
    "n_xna = len(raw_df[raw_df['XNA_PRESENT'] == 1])\n",
    "weights = torch.tensor([(1-((n_bases-n_xna)/(n_bases))), (1-(n_xna/(n_bases)))]).type(torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9220ad-177e-4ad3-8e4d-59bf5b0830ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating a model for XNA windows\n",
    "The following is designed to setup a model to identify windows of potential interest for XNA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58219e9-9e75-4423-bfa4-b12cf69032c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c0feb0-457b-45e6-b7e7-92ade95bcffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_training_dataframe(feature_read_list, window_size, n_strands_excluded = 10):\n",
    "    \n",
    "    # get the nmer window\n",
    "    nmer_dim = window_size*2 + 1\n",
    "    \n",
    "    # generate empty list for windowed parameters\n",
    "    windowed_params = []\n",
    "    \n",
    "    ind = 0\n",
    "    # for eacah strand in the subset of strands we care about,\n",
    "    for strand_features in feature_read_list[n_strands_excluded:]:\n",
    "        \n",
    "        # loop twice as many items as windows would fit in the strand\n",
    "        for i in range(int(len(strand_features)/nmer_dim)*2):\n",
    "            \n",
    "            # generate a random base position in the strand\n",
    "            random_base_pos = random.randrange(window_size, len(strand_features)-window_size-1, 1)\n",
    "            \n",
    "            # get the upper and lower indexes for the base window\n",
    "            upper = random_base_pos + window_size + 1\n",
    "            lower = random_base_pos - window_size\n",
    "            \n",
    "            # get the subset of the bases in the strand corresponding to the window\n",
    "            strand_features_subset = strand_features[lower:upper]\n",
    "            \n",
    "            #check if xna is present in the subset\n",
    "            xna_present = len(strand_features_subset[strand_features_subset['XNA_PRESENT'] > 0].index.tolist())>0\n",
    "            \n",
    "            # get the features for the xna window\n",
    "            features_2d = strand_features_subset.loc[:, strand_features_subset.columns != 'XNA_PRESENT']\n",
    "            \n",
    "            # convert to a long 1d array of features for each base in the window\n",
    "            features_long = [x for xs in features_2d.values for x in xs]\n",
    "            \n",
    "            # append the features and xna_present to the windowed_praams list\n",
    "            windowed_params.append({'XNA_PRESENT': int(xna_present), 'window_features':features_long})\n",
    "        ind += 1\n",
    "        print(percenttobar(ind/len(feature_read_list[n_strands_excluded:])) + \"{}/{}     \".format(ind, len(feature_read_list[n_strands_excluded:])),end='\\r')\n",
    "    print(percenttobar(1))\n",
    "        \n",
    "    \n",
    "    # generate a dataframe of the windowed params\n",
    "    window_df = pd.DataFrame(windowed_params)\n",
    "    \n",
    "    # get the features of the windowed_dataframe\n",
    "    window_df_features = pd.DataFrame.from_dict(dict(zip(window_df['window_features'].index, window_df['window_features'].values))).T\n",
    "    \n",
    "    # make a column where the XNA is present and reset to window_df\n",
    "    window_df_features['XNA_PRESENT'] = window_df['XNA_PRESENT']\n",
    "    window_df= window_df_features\n",
    "    \n",
    "    # Get all the windows that have an XNA\n",
    "    xna_windows = window_df[window_df['XNA_PRESENT'] == 1]\n",
    "    \n",
    "    # Get all the windows without XNA\n",
    "    rand_windows = window_df[window_df['XNA_PRESENT'] == 0]#.sample(n=len(xna_windows), random_state=0)\n",
    "    \n",
    "    # combine into a single dataframe\n",
    "    training_df = pd.concat([xna_windows, rand_windows]).reset_index(drop=True)\n",
    "    \n",
    "    return training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f90ca-00cf-46ef-8844-809964c1df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|=======             |  37.925%                3103/8182     \r"
     ]
    }
   ],
   "source": [
    "training_df = extract_training_dataframe(feature_read_list, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fd7cd-6658-45be-9fe6-e94c5796c45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_component_explained_variance(component_range, scaled_features):\n",
    "    '''\n",
    "    plot_component_explained_variances generates plots of the explained variance as\n",
    "    a function of PCA components by using find_pca_components.\n",
    "    \n",
    "    Parameters:\n",
    "    Component_range: max number of components to examine.\n",
    "    scaled_features: features that have been scaled with standardscaler\n",
    "    \n",
    "    Returns:\n",
    "    N/A\n",
    "    '''\n",
    "\n",
    "    component_list = list(np.arange(1,component_range, 1))\n",
    "    explained_variances = find_pca_components(component_list, scaled_features)\n",
    "\n",
    "    dy = np.diff(explained_variances)\n",
    "    dx = np.diff(component_list)\n",
    "\n",
    "    deriv = dy/dx\n",
    "    fig, ax = plt.subplots(1,2, figsize = (10,5))\n",
    "    ax[0].plot(component_list, explained_variances)\n",
    "    ax[0].grid()\n",
    "    ax[0].set_title('Total Explained Variance Ratio vs n_components')\n",
    "    ax[0].set_xlabel('n_components')\n",
    "    ax[0].set_ylabel('Total Explained Variance Ratio')\n",
    "    ax[1].plot(component_list[1:], dy/dx)\n",
    "    ax[1].grid()\n",
    "    ax[1].set_title('Rate of change of EV vs n_components')\n",
    "    ax[1].set_xlabel('n_components')\n",
    "    ax[1].set_ylabel('Rate of Change of EV Ratio')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4167b-a95b-4967-b346-ac87642703e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = training_df.loc[:, training_df.columns != 'XNA_PRESENT']\n",
    "labels = training_df['XNA_PRESENT']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_features = features.copy()\n",
    "scaled_features = pd.DataFrame(scaler.fit_transform(scaled_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bd14b-926e-4108-92d8-ef05e98666ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_component_explained_variance(50, scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acd7f3-70f5-41ea-b34e-818678b12db8",
   "metadata": {
    "tags": []
   },
   "source": [
    "From this, we can then generate an ideal PCA that maximizes EVR and minimizes components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609f9d7-cdfe-4ca4-8427-be2803ae5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of components\n",
    "comp = 26\n",
    "\n",
    "# generate PCA\n",
    "pca = PCA(n_components = comp, random_state=GLOBAL_RANDOM_STATE)\n",
    "\n",
    "# fit the scaled features to the pca\n",
    "pca.fit(scaled_features)\n",
    "\n",
    "# transform the features with pca\n",
    "x_pca = pca.transform(scaled_features)\n",
    "\n",
    "# get the explained variance ratios\n",
    "evrs = pca.explained_variance_ratio_\n",
    "\n",
    "# get the PCA datagrame\n",
    "pca_df = pd.DataFrame(x_pca)\n",
    "\n",
    "#reset the index of labels. Not sure why i have this here.\n",
    "labels.reset_index(drop=True)\n",
    "\n",
    "# split the pca features and labels to train-test, size 30%\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(pca_df,\n",
    "                                          labels,\n",
    "                                          test_size=0.0001,\n",
    "                                          random_state = GLOBAL_RANDOM_STATE)\n",
    "\n",
    "print(\"Component Variance Ratio: \", evrs)\n",
    "print(\"Total Explained Variance Ratio: \", evrs.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98727f05-f44f-42fc-a6a2-32251e4f2717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pk \n",
    "pk.dump(pca, open('/media/sebastian/Slepnir/xenofind_datasets/Working_directory_PZ/model_training/Models/window_model_v1/'+\"pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728254c-5bd0-4430-a86b-19321e654b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model \n",
    "\n",
    "# Convert training data to tensors\n",
    "tr_x_tensor = torch.tensor(x_tr.values).type(torch.float)\n",
    "tr_y_tensor = torch.tensor(np.asarray(y_tr)).type(torch.LongTensor)\n",
    "\n",
    "# generate the dataloader\n",
    "training_dataset = torch.utils.data.TensorDataset(tr_x_tensor, tr_y_tensor)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size = int(len(tr_x_tensor)/4), shuffle=True)\n",
    "\n",
    "# Convert testing data to tensors\n",
    "te_x_tensor = torch.tensor(x_te.values).type(torch.float).to(device)\n",
    "te_y_tensor = torch.tensor(np.asarray(y_te)).type(torch.LongTensor).to(device)\n",
    "\n",
    "# PARAMS FOR 7-mer:\n",
    "# number of features\n",
    "feature_num = tr_x_tensor.shape[1]\n",
    "out_features = 2\n",
    "epochs = 1000\n",
    "l_rate = .01\n",
    "rs=42\n",
    "nl_list = [52, 78, 13]\n",
    "loss_fxn = nn.CrossEntropyLoss()\n",
    "actv_fxn = nn.Tanh()\n",
    "\n",
    "# generate the window model. \n",
    "window_model = PyTorchClassifier(device=device,\n",
    "                            n_features = feature_num,\n",
    "                            out_features = out_features,\n",
    "                            nl_list = nl_list,\n",
    "                            activation_function = actv_fxn,\n",
    "                            loss_function = loss_fxn,\n",
    "                            n_epochs=epochs,\n",
    "                            learning_rate=l_rate,\n",
    "                            random_state=rs)\n",
    "#window_model.load_model_state(model_dir + 'prelim_window_model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0b462-51b7-4f8a-b10c-bf55dd9ee080",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Param optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e87ce9b-58f1-433c-a65c-6cbeedbee2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.01, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 1, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.5, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.1, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.05, 42),\n",
       " ('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.01, 42)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "param_dict = {'device':[device],\n",
    "              'n_features':[comp],\n",
    "              'out_features':[2],\n",
    "              'nl_list':[[comp^2, comp, int(comp/2)],\n",
    "                         [int(((comp-1)^2 + (comp-1)) / 2), comp^2, comp*2, int(comp/2)],\n",
    "                         [comp*2, comp*3, int(comp/2)],\n",
    "                         [int(comp/2)],\n",
    "                         [comp*2]],\n",
    "              'activation_function':[nn.Tanh()],\n",
    "              'loss_function':[nn.CrossEntropyLoss(), nn.CrossEntropyLoss(weight=weights)],\n",
    "              'epochs':[12],\n",
    "              'learning_rate':[1, .5, .1, .05, .01],\n",
    "              'random_state':[42]}\n",
    "\n",
    "param_keys = list(param_dict.keys())\n",
    "param_lists = []\n",
    "\n",
    "for key in param_keys:\n",
    "    value_list = param_dict[key]\n",
    "    param_lists.append(value_list)\n",
    "    \n",
    "model_combos = list(itertools.product(*param_lists))\n",
    "model_combos[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb20074d-95f5-4331-bbd1-ae42a297bb74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2A===============  |  91.667%                  11/12               49/50      "
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "# Iteration index for keeping progress\n",
    "i = 0\n",
    "\n",
    "# Loop through each possible combination of parameters.\n",
    "for params in model_combos:\n",
    "\n",
    "    # Print percentage progress\n",
    "    print(\"{}                    {}/{}      \".format(percenttobar(i/len(model_combos)), i, len(model_combos)),end='\\r')\n",
    "    \n",
    "    # Generate the model from the current parameters\n",
    "    test_model = PyTorchClassifier(*params)\n",
    "    \n",
    "    # Here, we generate the key of the model based on it's params\n",
    "    key = str(params)\n",
    "    # Train the model\n",
    "    test_model.train_model(training_dataloader)\n",
    "    \n",
    "    # Test the model on training and testing data\n",
    "    train_loss, train_acc = test_model.test_model(tr_x_tensor[:1000].to(device), tr_y_tensor[:1000].to(device))\n",
    "    test_loss, test_acc = test_model.test_model(te_x_tensor, te_y_tensor)\n",
    "    \n",
    "    # Return the results to the dictionary\n",
    "    results_dict[key] = [train_acc, test_acc]\n",
    "    torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Incriment the progress tracker\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c2a8a61-92ab-432a-a0d5-9238d45321a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 1, 42)</th>\n",
       "      <td>0.870</td>\n",
       "      <td>0.871123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42)</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.841705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.5, 42)</th>\n",
       "      <td>0.837</td>\n",
       "      <td>0.817089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 1, 42)</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.796023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42)</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.762980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42)</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.765307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42)</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.753053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.1, 42)</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.05, 42)</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.698687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42)</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.715315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42)</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.665141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42)</th>\n",
       "      <td>0.671</td>\n",
       "      <td>0.657840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42)</th>\n",
       "      <td>0.617</td>\n",
       "      <td>0.600472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42)</th>\n",
       "      <td>0.616</td>\n",
       "      <td>0.594822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42)</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.591166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.1, 42)</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.587885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(), 12, 0.01, 42)</th>\n",
       "      <td>0.589</td>\n",
       "      <td>0.599485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.05, 42)</th>\n",
       "      <td>0.588</td>\n",
       "      <td>0.570946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42)</th>\n",
       "      <td>0.581</td>\n",
       "      <td>0.586213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42)</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.529992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42)</th>\n",
       "      <td>0.479</td>\n",
       "      <td>0.482959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 1, 42)</th>\n",
       "      <td>0.449</td>\n",
       "      <td>0.454752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.5, 42)</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.466020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42)</th>\n",
       "      <td>0.328</td>\n",
       "      <td>0.309944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossEntropyLoss(), 12, 0.01, 42)</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0         1\n",
       "('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(...  0.870  0.871123\n",
       "('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntr...  0.857  0.841705\n",
       "('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(...  0.837  0.817089\n",
       "('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(...  0.803  0.796023\n",
       "('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntr...  0.781  0.762980\n",
       "('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntr...  0.778  0.765307\n",
       "('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(...  0.747  0.753053\n",
       "('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(...  0.713  0.711262\n",
       "('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(...  0.704  0.698687\n",
       "('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(...  0.702  0.715315\n",
       "('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntr...  0.672  0.665141\n",
       "('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(...  0.671  0.657840\n",
       "('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossE...  0.617  0.600472\n",
       "('cuda', 26, 2, [13], Tanh(), CrossEntropyLoss(...  0.616  0.594822\n",
       "('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntr...  0.594  0.591166\n",
       "('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossE...  0.594  0.587885\n",
       "('cuda', 26, 2, [52], Tanh(), CrossEntropyLoss(...  0.589  0.599485\n",
       "('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossE...  0.588  0.570946\n",
       "('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossE...  0.581  0.586213\n",
       "('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntr...  0.530  0.529992\n",
       "('cuda', 26, 2, [24, 26, 13], Tanh(), CrossEntr...  0.479  0.482959\n",
       "('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntr...  0.449  0.454752\n",
       "('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntr...  0.435  0.466020\n",
       "('cuda', 26, 2, [52, 78, 13], Tanh(), CrossEntr...  0.328  0.309944\n",
       "('cuda', 26, 2, [1, 24, 52, 13], Tanh(), CrossE...  0.054  0.055556"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results_dict).T\n",
    "results_df.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d38c7-0ae1-4ddf-9560-25a3efb1a594",
   "metadata": {},
   "source": [
    "#### window model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a8392-ded8-4c8e-94b6-d65a163fe542",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a95ab-e225-40eb-9c56-89522176cb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_model.train_model(training_dataloader)\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509217a-5b56-43d2-a656-c02fb77e6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and report the loss and accuracies.\n",
    "train_loss, train_acc = window_model.test_model(tr_x_tensor[:1000].to(device), tr_y_tensor[:1000].to(device))\n",
    "test_loss, test_acc = window_model.test_model(te_x_tensor, te_y_tensor)\n",
    "\n",
    "print(\"Training: {}, Testing: {}\".format(train_acc, test_acc))\n",
    "# generate a confusion matrix for the overall model. \n",
    "cm = confusion_matrix(te_y_tensor.tolist(), torch.softmax(window_model.model(torch.tensor(x_te.values).type(torch.float).to(device)), dim=1).argmax(dim=1).tolist())\n",
    "fig, ax = plt.subplots(1, figsize=(2.5, 2))\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d46cc-b4dc-44c0-aba8-6e5f7938e569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_model.save_model_state(model_dir, 'window_model_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b4387-c0ca-4c9b-b804-bfa9953be952",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### preliminary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ad709-72d5-4971-9053-821c6ee81cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an empty list to hold the number of windows classified.\n",
    "n_classified = []\n",
    "\n",
    "# for each of the first ten consensus strands.\n",
    "for j in range(10):\n",
    "    \n",
    "    test_consensus = feature_read_list[j]\n",
    "    # batch the bases into windows of size seven\n",
    "    base_windows= [test_consensus[i:int(i+window_size*2+1)] for i in range(0, len(test_consensus), int(window_size*2+1))]\n",
    "    \n",
    "    # set up lists for window classes and features\n",
    "    window_classes = []\n",
    "    window_features = []\n",
    "    \n",
    "    # for each window minus the potentially inconsistently sized one,\n",
    "    for base_window in base_windows[:-1]:\n",
    "        \n",
    "        # generate an empty list for the window's 1d features\n",
    "        window_sub_features = []\n",
    "        \n",
    "        # check if there's an XNA, append a 1 to the classes if so.\n",
    "        if len(base_window[base_window['XNA_PRESENT'] > 0]) > 0:\n",
    "            window_classes.append(1)\n",
    "        else:\n",
    "            window_classes.append(0)\n",
    "            \n",
    "        # loop through each base features, and extend the features to the 1d feature array\n",
    "        for base in base_window.drop(columns=['XNA_PRESENT']).values:\n",
    "            window_sub_features.extend(base)\n",
    "            \n",
    "        # append the window's 1d features to the list.\n",
    "        window_features.append(window_sub_features)\n",
    "    \n",
    "    \n",
    "    # Create a scaler for the window's features\n",
    "    scale = scaler.fit_transform(window_features)\n",
    "    \n",
    "    # generate the features and labels as tensors\n",
    "    strand_features = torch.tensor(pca.transform(scale)).type(torch.float).to(device)\n",
    "    strand_labels = torch.tensor(np.asarray(window_classes)).type(torch.LongTensor).to(device)\n",
    "    \n",
    "    # generate the logits of the model for the fiven features and labels\n",
    "    strand_logits = window_model.model(strand_features)\n",
    "\n",
    "    # get the predictions\n",
    "    strand_predictions = torch.softmax(strand_logits, dim=1).argmax(dim=1)\n",
    "    \n",
    "    # get the predictions list\n",
    "    predictions = strand_predictions.tolist()\n",
    "    \n",
    "    # get the true labels\n",
    "    trues = strand_labels.tolist()\n",
    "    \n",
    "    # get the predicted series\n",
    "    pred_series=pd.Series(predictions)\n",
    "\n",
    "    # generate a confusion matrix for the current strand for validation. \n",
    "    cm = confusion_matrix(trues, predictions)\n",
    "    fig, ax = plt.subplots(1, figsize=(2.5, 2))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "    ax.set_xlabel(\"Predicted Labels\")\n",
    "    ax.set_ylabel(\"True Labels\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    \n",
    "    # print the window. \n",
    "    print(list(zip(np.asarray(pred_series[pred_series> 0].index.tolist())*(window_size*2+1), (np.asarray(pred_series[pred_series> 0].index.tolist())+1)*(window_size*2+1))))\n",
    "    plt.show()\n",
    "    n_classified.append(len(pred_series[pred_series> 0].index.tolist()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270c6b6-8dae-4718-af95-b72fb80e9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the cuda memory cache.\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c0837-e472-4ee4-9beb-85fee6ca2b0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating a model for bases in XNA window\n",
    "The following is designed to set up a model for the XNA within a window to differentiate once a window has been found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446da77a-b128-4d9f-a0b8-ad9fae859d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xna_window_data(feature_read_list, nmer_dim=7, n_strands_excluded = 10):\n",
    "    '''\n",
    "    generate_xna_window_data is designed to extract the features of all the surrounding bases\n",
    "    of an xna given a defined window.\n",
    "    \n",
    "    Parameters:\n",
    "    feature_read_list: a list of pandas dataframes that have the strands and their features\n",
    "    nmer_dim: the window size, (number of bases on each side of the xna + 1), Default = 7\n",
    "    n_strands_excluded: number of strands excluded from the data extraction. Default = 10\n",
    "    \n",
    "    Returns:\n",
    "    pandas dataframe containing the features of all the bases in each window and their classes\n",
    "    '''\n",
    "    # generate empty list to hold xna windows\n",
    "    xna_windows = []\n",
    "    \n",
    "    # loop throuch each strand\n",
    "    for strand_features in feature_read_list[n_strands_excluded:]:\n",
    "\n",
    "        # get the xna base position in the strand\n",
    "        xna_base_pos = strand_features[strand_features['XNA_PRESENT'] > 0].index[0]\n",
    "        \n",
    "        # get the upper and lower bounds of the window\n",
    "        upper_bound = xna_base_pos + nmer_dim\n",
    "        lower_bound = xna_base_pos - nmer_dim +1\n",
    "        \n",
    "        # get all the bases within that band\n",
    "        xna_windows.append(strand_features[lower_bound:upper_bound])\n",
    "\n",
    "    # generate a dataframe of the extracted bases\n",
    "    base_training_df = pd.concat(xna_windows).reset_index(drop=True)\n",
    "    \n",
    "    return base_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ab215-525b-4129-ae3f-2481f1fbd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_training_df = generate_xna_window_data(feature_read_list, 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea976b-ca02-4446-a81b-23ca8f7fcac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = base_training_df.loc[:, base_training_df.columns != 'XNA_PRESENT']\n",
    "base_labels = base_training_df['XNA_PRESENT']\n",
    "\n",
    "base_scaler = StandardScaler()\n",
    "\n",
    "base_scaled_features = base_features.copy()\n",
    "base_scaled_features = pd.DataFrame(base_scaler.fit_transform(base_scaled_features))\n",
    "\n",
    "#plot_component_explained_variance(50, base_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e83dbe-ddc8-4daa-8866-da8fdcb89465",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pca = PCA(n_components = 26, random_state=GLOBAL_RANDOM_STATE)\n",
    "b_pca.fit(base_scaled_features)\n",
    "b_x_pca = b_pca.transform(base_scaled_features)\n",
    "b_evrs = b_pca.explained_variance_ratio_\n",
    "\n",
    "base_labels.reset_index(drop=True)\n",
    "\n",
    "print(\"Component Variance Ratio: \", b_evrs)\n",
    "print(\"Total Explained Variance Ratio: \", b_evrs.sum())\n",
    "\n",
    "b_pca_df = pd.DataFrame(b_x_pca)\n",
    "base_labels.reset_index(drop=True)\n",
    "b_x_tr, b_x_te, b_y_tr, b_y_te = train_test_split(b_pca_df,\n",
    "                                          base_labels,\n",
    "                                          test_size=.001,\n",
    "                                          random_state = GLOBAL_RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4006ed-565c-4f44-9daf-5aba014df463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pk \n",
    "pk.dump(b_pca, open('/media/sebastian/Slepnir/xenofind_datasets/Working_directory_PZ/model_training/Models/base_model_v1/'+\"pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2db159c-57de-44ca-be2a-b2082cbe37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to tensors\n",
    "tr_x_tensor = torch.tensor(b_x_tr.values).type(torch.float)\n",
    "tr_y_tensor = torch.tensor(np.asarray(b_y_tr)).type(torch.LongTensor)\n",
    "\n",
    "# generate the dataloader\n",
    "training_dataset = torch.utils.data.TensorDataset(tr_x_tensor, tr_y_tensor)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size = int(len(tr_x_tensor)), shuffle=True)\n",
    "\n",
    "# Convert testing data to tensors\n",
    "te_x_tensor = torch.tensor(b_x_te.values).type(torch.float).to(device)\n",
    "te_y_tensor = torch.tensor(np.asarray(b_y_te)).type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "# number of features\n",
    "feature_num = tr_x_tensor.shape[1]\n",
    "out_features = 2\n",
    "epochs = 10\n",
    "l_rate = .1\n",
    "rs=42\n",
    "nl_list = [676, 338, 100, 10]\n",
    "\n",
    "# optuna - hyperparameter optimization\n",
    "\n",
    "loss_fxn = nn.CrossEntropyLoss(weight=weights)\n",
    "actv_fxn = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "befd035c-1ab8-4331-a06a-e18daf65782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XNA Identifier Model Training: 0.23793749235358888, Testing: 0.24299065420560748\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = PyTorchClassifier(device=device,\n",
    "                            n_features = feature_num,\n",
    "                            out_features = out_features,\n",
    "                            nl_list = nl_list,\n",
    "                            activation_function = actv_fxn,\n",
    "                            loss_function = loss_fxn,\n",
    "                            n_epochs=epochs,\n",
    "                            learning_rate=l_rate,\n",
    "                            random_state=rs)\n",
    "\n",
    "base_model.train_model(training_dataloader)\n",
    "train_loss, train_acc = base_model.test_model(tr_x_tensor.to(device), tr_y_tensor.to(device))\n",
    "test_loss, test_acc = base_model.test_model(te_x_tensor, te_y_tensor)\n",
    "\n",
    "print(\"XNA Identifier Model Training: {}, Testing: {}\".format(train_acc, test_acc))\n",
    "#print(\"Training misclassified/strand: {}, Testing misclassified/strand: {}\".format(1-(132-train_acc.item()*132),1-(132-test_acc.item()*132)))\n",
    "test_consensus = feature_read_list[0]\n",
    "#bPTmodel.model(torch.tensor(pca.transform(test_consensus.loc[:, test_consensus.columns != 'XNA_PRESENT'])).type(torch.float).to(device))[66]\n",
    "\n",
    "cm = confusion_matrix(te_y_tensor.tolist(), torch.softmax(base_model.model(torch.tensor(b_x_te.values).type(torch.float).to(device)), dim=1).argmax(dim=1).tolist())\n",
    "fig, ax = plt.subplots(1, figsize=(2.5, 2))\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1da1bf1d-8cf1-4478-9fa4-bc5fe9768a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (35, 42), (49, 56), (56, 63), (70, 77), (77, 84), (84, 91), (91, 98), (105, 112), (112, 119), (119, 126)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 35, 36, 37, 39, 40, 41, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 105, 107, 108, 109, 110, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124]\n",
      "\n",
      "Sequence 2:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (42, 49), (49, 56), (63, 70), (70, 77), (77, 84), (84, 91), (91, 98), (105, 112), (112, 119), (119, 126)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 105, 106, 107, 108, 109, 110, 111, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124]\n",
      "\n",
      "Sequence 3:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (28, 35), (42, 49), (56, 63), (70, 77), (77, 84), (84, 91), (91, 98), (98, 105), (105, 112), (112, 119)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 28, 29, 30, 31, 32, 34, 42, 43, 44, 46, 47, 48, 56, 57, 58, 59, 60, 61, 62, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 107, 108, 109, 110, 113, 114, 116, 117, 118]\n",
      "\n",
      "Sequence 4:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (28, 35), (49, 56), (63, 70), (70, 77), (77, 84), (91, 98), (105, 112), (112, 119), (119, 126)]\n",
      "Identified Bases: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 50, 51, 52, 53, 54, 55, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 91, 92, 93, 94, 95, 96, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124]\n",
      "\n",
      "Sequence 5:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (28, 35), (49, 56), (63, 70), (70, 77), (77, 84), (84, 91), (91, 98), (105, 112), (112, 119)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 28, 29, 30, 31, 32, 33, 34, 49, 51, 52, 53, 54, 55, 63, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118]\n",
      "\n",
      "Sequence 6:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (28, 35), (42, 49), (49, 56), (56, 63), (63, 70), (70, 77), (77, 84), (91, 98), (98, 105), (105, 112), (112, 119), (119, 126)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 42, 43, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124]\n",
      "\n",
      "Sequence 7:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (35, 42), (42, 49), (49, 56), (63, 70), (70, 77), (77, 84), (84, 91), (91, 98), (105, 112), (112, 119)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 26, 27, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 105, 107, 108, 109, 110, 113, 114, 116, 117, 118]\n",
      "\n",
      "Sequence 8:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (28, 35), (42, 49), (63, 70), (70, 77), (77, 84), (91, 98), (98, 105), (112, 119), (119, 126)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 42, 43, 46, 47, 48, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124]\n",
      "\n",
      "Sequence 9:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (28, 35), (42, 49), (49, 56), (56, 63), (63, 70), (70, 77), (77, 84), (91, 98), (105, 112), (112, 119)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 83, 91, 92, 93, 94, 95, 96, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 118]\n",
      "\n",
      "Sequence 10:\n",
      "Identified Regions: [(0, 7), (7, 14), (14, 21), (21, 28), (28, 35), (49, 56), (56, 63), (63, 70), (70, 77), (77, 84), (84, 91), (91, 98), (98, 105), (105, 112), (112, 119), (119, 126)]\n",
      "Identified Bases: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classified = []\n",
    "\n",
    "# loop through the first ten strands\n",
    "for j in range(10):\n",
    "    \n",
    "    # get the strand data\n",
    "    test_consensus = feature_read_list[j]\n",
    "    \n",
    "    #---- ------ ---- ------ WINDOW MODELING ---- ------ ----- ------ ----- #\n",
    "    # batch the bases into windows of size seven\n",
    "    base_windows= [test_consensus[i:int(i+window_size*2+1)] for i in range(0, len(test_consensus), int(window_size*2+1))]\n",
    "    \n",
    "    # set up lists for window classes and features\n",
    "    window_classes = []\n",
    "    window_features = []\n",
    "    \n",
    "    # for each window minus the potentially inconsistently sized one,\n",
    "    for base_window in base_windows[:-1]:\n",
    "        \n",
    "        # generate an empty list for the window's 1d features\n",
    "        window_sub_features = []\n",
    "        \n",
    "        # check if there's an XNA, append a 1 to the classes if so.\n",
    "        if len(base_window[base_window['XNA_PRESENT'] > 0]) > 0:\n",
    "            window_classes.append(1)\n",
    "        else:\n",
    "            window_classes.append(0)\n",
    "            \n",
    "        # loop through each base features, and extend the features to the 1d feature array\n",
    "        for base in base_window.drop(columns=['XNA_PRESENT']).values:\n",
    "            window_sub_features.extend(base)\n",
    "            \n",
    "        # append the window's 1d features to the list.\n",
    "        window_features.append(window_sub_features)\n",
    "    \n",
    "    # Create a scale of the window features + convert to tensors for features and labels\n",
    "    scale = scaler.fit_transform(window_features)\n",
    "    strand_features = torch.tensor(pca.transform(scale)).type(torch.float).to(device)\n",
    "    strand_labels = torch.tensor(np.asarray(window_classes)).type(torch.LongTensor).to(device)\n",
    "    \n",
    "    # pass window features to models for strands\n",
    "    strand_logits = window_model.model(strand_features)\n",
    "\n",
    "    # Get the predictions for the model\n",
    "    strand_predictions = torch.softmax(strand_logits, dim=1).argmax(dim=1)\n",
    "    \n",
    "    #convert the predictions to a list\n",
    "    predictions = strand_predictions.tolist()\n",
    "    \n",
    "    # get the true window predictions as a list\n",
    "    trues = strand_labels.tolist()\n",
    "    \n",
    "    # convert the predictions to a series\n",
    "    pred_series=pd.Series(predictions)\n",
    "    \n",
    "    # get the lsit of windows predicted\n",
    "    idd_windows = list(zip(np.asarray(pred_series[pred_series> 0].index.tolist())*(window_size*2+1), (np.asarray(pred_series[pred_series> 0].index.tolist())+1)*(window_size*2+1)))\n",
    "    \n",
    "    # ------ ------ ------ WINDOW BASE MODELING ------------------------#\n",
    "    print(\"Sequence {}:\".format(j+1))\n",
    "    \n",
    "    # generate an empty base list\n",
    "    base_list = []\n",
    "    \n",
    "    # for each window in the predicted windows:\n",
    "    for window in idd_windows:\n",
    "        \n",
    "        # get the base region from the strand as defined in the window\n",
    "        xna_region = test_consensus[window[0]:window[1]]\n",
    "        \n",
    "        # get the features and classes\n",
    "        xna_region_features = xna_region.loc[:, xna_region.columns != 'XNA_PRESENT']\n",
    "        xna_region_classes = xna_region['XNA_PRESENT']\n",
    "        \n",
    "        # conform those to the base scaler\n",
    "        base_scale = base_scaler.fit_transform(xna_region_features)\n",
    "        \n",
    "        # get the features and labels as tensors\n",
    "        region_features = torch.tensor(b_pca.transform(base_scale)).type(torch.float).to(device)\n",
    "        region_labels = torch.tensor(np.asarray(xna_region_classes)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        # generate the logits with the base_model\n",
    "        region_logits = base_model.model(region_features)\n",
    "        \n",
    "        # get the predicted base classes\n",
    "        xna_predictions = torch.softmax(region_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "        # get the list of predictions\n",
    "        xna = xna_predictions.tolist()\n",
    "        \n",
    "        # get the true bases\n",
    "        true_xna = region_labels.tolist()\n",
    "        \n",
    "        # get the series of predicted bases\n",
    "        pred_xna_series = pd.Series(xna)\n",
    "        \n",
    "        # extend the identified base list with all bases identified as XNA by the model\n",
    "        base_list.extend((np.asarray(pred_xna_series[pred_xna_series >0].index.tolist()) + window[0]).tolist())\n",
    "        \n",
    "    # report the identified regions and bases\n",
    "    print(\"Identified Regions: {}\".format(idd_windows))\n",
    "    print(\"Identified Bases: {}\".format(base_list))\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bd98832-74ea-4327-a85e-34767300ab40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/sebastian/Slepnir/xenofind_datasets/Working_directory_PZ/model_training/Models/base_model_v1/state.pt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#window_model.save_model_state(model_dir, 'window_model_v1')\n",
    "base_model.save_model_state(model_dir, 'base_model_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3eaf4c-8444-484c-b867-69715c987a32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### External Dataset Validaton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c8acd-4d86-4a28-9ba9-f77b3e599493",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e9f820-7700-48f9-9cdc-b8261ff82971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ClassifierNetwork:\n\tMissing key(s) in state_dict: \"linear_layer_stack.8.weight\", \"linear_layer_stack.8.bias\". \n\tsize mismatch for linear_layer_stack.6.weight: copying a param with shape torch.Size([2, 55]) from checkpoint, the shape in current model is torch.Size([10, 55]).\n\tsize mismatch for linear_layer_stack.6.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m      9\u001b[0m actv_fxn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTanh()\n\u001b[1;32m     12\u001b[0m loaded_window_model \u001b[38;5;241m=\u001b[39m PyTorchClassifier(device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     13\u001b[0m                             n_features \u001b[38;5;241m=\u001b[39m feature_num,\n\u001b[1;32m     14\u001b[0m                             out_features \u001b[38;5;241m=\u001b[39m out_features,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m                             learning_rate\u001b[38;5;241m=\u001b[39ml_rate,\n\u001b[1;32m     20\u001b[0m                             random_state\u001b[38;5;241m=\u001b[39mrs)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloaded_window_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprelim_window_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 199\u001b[0m, in \u001b[0;36mPyTorchClassifier.load_model_state\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mload_model_state loads the model state from a given path.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03mthe loaded model, in evaluation state\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# load the model from the path\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# set the model into evaluation mode\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ClassifierNetwork:\n\tMissing key(s) in state_dict: \"linear_layer_stack.8.weight\", \"linear_layer_stack.8.bias\". \n\tsize mismatch for linear_layer_stack.6.weight: copying a param with shape torch.Size([2, 55]) from checkpoint, the shape in current model is torch.Size([10, 55]).\n\tsize mismatch for linear_layer_stack.6.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "# Load the window_model\n",
    "feature_num = 26\n",
    "out_features = 2\n",
    "epochs = 1000\n",
    "l_rate = .01\n",
    "rs=42\n",
    "nl_list = [52, 2704, 55, 10]\n",
    "loss_fxn = nn.CrossEntropyLoss()\n",
    "actv_fxn = nn.Tanh()\n",
    "\n",
    "\n",
    "loaded_window_model = PyTorchClassifier(device=device,\n",
    "                            n_features = feature_num,\n",
    "                            out_features = out_features,\n",
    "                            nl_list = nl_list,\n",
    "                            activation_function = actv_fxn,\n",
    "                            loss_function = loss_fxn,\n",
    "                            n_epochs=epochs,\n",
    "                            learning_rate=l_rate,\n",
    "                            random_state=rs)\n",
    "loaded_window_model.load_model_state(model_dir + 'prelim_window_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e93ef7-36ef-4b6e-8f63-7886e39f05ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierNetwork(\n",
       "  (linear_layer_stack): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=400, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the base model\n",
    "feature_num = 26\n",
    "out_features = 2\n",
    "epochs = 50\n",
    "l_rate = .1\n",
    "rs=42\n",
    "nl_list = [400, 200, 20]\n",
    "\n",
    "# optuna - hyperparameter optimization\n",
    "\n",
    "loss_fxn = nn.CrossEntropyLoss(weight=torch.tensor([.0075, .9925]).type(torch.float).to(device))\n",
    "actv_fxn = nn.Tanh()\n",
    "\n",
    "loaded_base_model = PyTorchClassifier(device=device,\n",
    "                            n_features = feature_num,\n",
    "                            out_features = out_features,\n",
    "                            nl_list = nl_list,\n",
    "                            activation_function = actv_fxn,\n",
    "                            loss_function = loss_fxn,\n",
    "                            n_epochs=epochs,\n",
    "                            learning_rate=l_rate,\n",
    "                            random_state=rs)\n",
    "loaded_base_model.load_model_state(model_dir+'prelim_base_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4cdc7d-fb04-4923-81b5-cbb760576e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe772844-71bf-40aa-847a-15f18b02da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle as pk\n",
    "DEVICE=(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "def run_check_device():\n",
    "    d = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\")\n",
    "    \n",
    "    DEVICE = d\n",
    "    return d\n",
    "\n",
    "\n",
    "def activ_func_parser(act_str):\n",
    "    '''\n",
    "    parses an activity function string. Currently only works with nn.tanh()\n",
    "    '''\n",
    "    if act_str == 'Tanh()':\n",
    "        return nn.Tanh()\n",
    "    else:\n",
    "        return nn.Tanh()\n",
    "\n",
    "    \n",
    "def loss_func_parser(loss_str, wt, device):\n",
    "    '''\n",
    "    parses a loss function string with weight and device. Currently only uses\n",
    "    nn.CrossEntropyLoss()\n",
    "    '''\n",
    "    if len(wt) > 1:\n",
    "        wt = torch.tensor(wt).type(torch.float).to(device)\n",
    "        if loss_str == 'CrossEntropyLoss()':\n",
    "            return nn.CrossEntropyLoss(weight = wt)\n",
    "    else:\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def get_model_params(model_dir):\n",
    "    '''\n",
    "    generates the model paramater touple from a given model directory.\n",
    "    assumes model directory contains 'params.txt'.\n",
    "    '''\n",
    "    DEVICE = run_check_device()\n",
    "    param_string = None\n",
    "    with open(model_dir+\"params.txt\", 'r') as f:\n",
    "        param_string = f.readline()\n",
    "\n",
    "    param_list = param_string.split(\"|\")\n",
    "\n",
    "    # Check if the device is matching the current device and update accordingly.\n",
    "\n",
    "    if param_list[0] == DEVICE:\n",
    "        DEVICE = param_list[0]\n",
    "    else:\n",
    "        param_list[0] = DEVICE\n",
    "\n",
    "    param_list[9] = ast.literal_eval(param_list[9]) # weights notation\n",
    "\n",
    "    param_list[1] = int(param_list[1]) # PCA features\n",
    "    param_list[2] = int(param_list[2]) # Classes\n",
    "    param_list[3] = ast.literal_eval(param_list[3]) # Network list\n",
    "    param_list[4] = activ_func_parser(param_list[4]) # activation function\n",
    "    param_list[5] = loss_func_parser(param_list[5], param_list[9], DEVICE) # loss function\n",
    "    param_list[6] = int(param_list[6]) # epochs\n",
    "    param_list[7] = float(param_list[7]) # learning rate\n",
    "    param_list[8] = int(param_list[8]) # random state\n",
    "\n",
    "\n",
    "    param_list = param_list[:-1]\n",
    "\n",
    "    return tuple(param_list)\n",
    "\n",
    "\n",
    "def load_models(window_model_dir, base_model_dir):\n",
    "    '''\n",
    "    this is very hastily written code and should be revised to be better. \n",
    "    forgive me :( -S\n",
    "    '''\n",
    "    run_check_device()\n",
    "    # open params:\n",
    "    window_model_params = get_model_params(window_model_dir)\n",
    "    base_model_params = get_model_params(base_model_dir)\n",
    "    \n",
    "    #generate the models\n",
    "    loaded_window_model = PyTorchClassifier(*window_model_params)\n",
    "    loaded_base_model = PyTorchClassifier(*base_model_params)\n",
    "    \n",
    "    #load the model states\n",
    "    loaded_window_model.load_model_state(window_model_dir + 'state.pt')\n",
    "    loaded_base_model.load_model_state(base_model_dir + 'state.pt')\n",
    "    \n",
    "    return loaded_window_model, loaded_base_model\n",
    "\n",
    "\n",
    "def load_pcas(window_model_dir, base_model_dir):\n",
    "    '''\n",
    "    Dave, I know this is bad code and bad ML but genuinely i am writing this on wednesday at 8:10 pm -S\n",
    "    '''\n",
    "    pca_window = pk.load(open(window_model_dir+\"pca.pkl\",'rb'))\n",
    "    pca_base = pk.load(open(base_model_dir+\"pca.pkl\", 'rb'))\n",
    "    return pca_window, pca_base\n",
    "\n",
    "\n",
    "def window_detection(window_model, read_feature_df, pca):\n",
    "    '''\n",
    "    uses a window model to detect xna windows from the data\n",
    "    '''\n",
    "    DEVICE = run_check_device()\n",
    "    # step 1: split the data into windows of size 7 ----------------\n",
    "    window_size = 7\n",
    "    windows = [read_feature_df[i:int(i+window_size)] for i in range(0, len(read_feature_df), int(window_size))]\n",
    "    \n",
    "    window_classes = []\n",
    "    window_features = []\n",
    "    \n",
    "    # for each window minus the potentially inconsistently sized one,\n",
    "    for base_window in windows[:-1]:\n",
    "        \n",
    "        # generate an empty list for the window's 1d features\n",
    "        window_sub_features = []\n",
    "        \n",
    "        # check if there's an XNA, append a 1 to the classes if so. When testing, there should never be anything but zeroes here.\n",
    "        if len(base_window[base_window['XNA_PRESENT'] > 0]) > 0:\n",
    "            window_classes.append(1)\n",
    "        else:\n",
    "            window_classes.append(0)\n",
    "            \n",
    "        # loop through each base features, and extend the features to the 1d feature array\n",
    "        for base in base_window.drop(columns=['XNA_PRESENT']).values:\n",
    "            window_sub_features.extend(base)\n",
    "            \n",
    "        # append the window's 1d features to the list.\n",
    "        window_features.append(window_sub_features)\n",
    "        \n",
    "    # step 2: scale the data.\n",
    "    window_scaler = StandardScaler()\n",
    "    scaled_features = window_scaler.fit_transform(window_features)\n",
    "    \n",
    "     # step 3as;lkvskvna;lkf: generate PCA - THIS IS BAD FORM AND SHOULD NOT BE DONE THIS WAY BUT TIME HAS FORCED MY HAND\n",
    "    #n_pca_features = window_model.n_features\n",
    "    #pca = PCA(n_components=n_pca_features, random_state = window_model.random_state)\n",
    "    #pca = PCA.fit_transform(scaled_features)\n",
    "    \n",
    "    # step 4: generate the feature tensor and label tensor\n",
    "    feature_tensor = torch.tensor(pca.transform(scaled_features)).type(torch.float).to(DEVICE)\n",
    "    # --> unuused because it is only for training rn:  label_tensor = torch.tensor(np.asarray(window_classes)).type(torch.LongTensor).to(DEVICE)\n",
    "    \n",
    "    # step 5: run the model!\n",
    "    window_logits = window_model.model(feature_tensor)\n",
    "    \n",
    "    # step 6: convert the model logits to predictions\n",
    "    window_predictions = torch.softmax(window_logits, dim=1).argmax(dim=1)\n",
    "    \n",
    "    # step 7: extract the predicted windows:\n",
    "    #convert the predictions to a list\n",
    "    predictions = window_predictions.tolist()\n",
    "\n",
    "    # convert the predictions to a series\n",
    "    pred_series=pd.Series(predictions)\n",
    "    \n",
    "    # get the lsit of windows predicted\n",
    "    idd_windows = list(zip(np.asarray(pred_series[pred_series> 0].index.tolist())*(window_size), (np.asarray(pred_series[pred_series> 0].index.tolist())+1)*(window_size)))\n",
    "    \n",
    "    return idd_windows\n",
    "    \n",
    "\n",
    "def windowed_base_detection(base_model, window, read_feature_df, pca):\n",
    "    '''\n",
    "    uses a base model to detect bases from a window\n",
    "    '''\n",
    "    DEVICE = run_check_device()\n",
    "    \n",
    "    # step 1: generate the detection region from the window\n",
    "    window_bases = read_feature_df[window[0]:window[1]]\n",
    "    \n",
    "    # step 2: get the features and classes\n",
    "    window_base_features = window_bases.loc[:, window_bases.columns != 'XNA_PRESENT']\n",
    "    window_base_features = window_bases['XNA_PRESENT']\n",
    "\n",
    "\n",
    "    # step 3: scale the data:\n",
    "    base_scaler = StandardScaler()\n",
    "    \n",
    "    # For some heavens forsaken reason, this is the only way this runs and it wont work separated\n",
    "    base_scale = StandardScaler().fit_transform(window_bases.loc[:, window_bases.columns != 'XNA_PRESENT'])\n",
    "\n",
    "        \n",
    "    # step 4: generate PCA - THIS IS BAD FORM AND SHOULD NOT BE DONE THIS WAY BUT TIME HAS FORCED MY HAND\n",
    "    #n_pca_features = base_model.n_features\n",
    "    #pca = PCA(n_components=n_pca_features, random_state = window_model.random_state)\n",
    "    #pca.fit(scaled_features)\n",
    "    \n",
    "    # step 5: generate the feature and label tensors\n",
    "    region_features = torch.tensor(pca.transform(base_scale)).type(torch.float).to(DEVICE)\n",
    "    # UNUSED    region_labels = torch.tensor(np.asarray(xna_region_classes)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "    # step 6: Run the model! \n",
    "    region_logits = base_model.model(region_features)\n",
    "        \n",
    "    # step 7: get the predicted base classes\n",
    "    xna_predictions = torch.softmax(region_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "    # step 8: get the list of predictions\n",
    "    xna = xna_predictions.tolist()\n",
    "\n",
    "    # get the series of predicted bases\n",
    "    pred_xna_series = pd.Series(xna)\n",
    "    \n",
    "    # return a list of the bases id'd as XNA. \n",
    "    return (np.asarray(pred_xna_series[pred_xna_series >0].index.tolist()) + window[0]).tolist()\n",
    "                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb6c0ef-b2f0-4125-8f4f-cc40cf9c347b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387304d1-8281-4f57-8d90-34b27c15d191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_model_dir = '/media/sebastian/Slepnir/xenofind_datasets/Working_directory_PZ/model_training/Models/window_model_v1/'\n",
    "base_model_dir = '/media/sebastian/Slepnir/xenofind_datasets/Working_directory_PZ/model_training/Models/base_model_v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3020d348-9526-4d55-882a-16f29066ec64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the models and load the pca I KNOW THATS NOT GOOD BUT I NEED TO DO IT\n",
    "w_m, b_m = modeling.load_models(window_model_dir, base_model_dir)\n",
    "w_p, b_p = modeling.load_pcas(window_model_dir, base_model_dir)\n",
    "\n",
    "# gEnerate the windowwZsd\n",
    "windows = modeling.window_detection(w_m, feature_read_list[0], w_p)\n",
    "\n",
    "# GENERATE THE aoutput ductuinary pof identified windows and their bases\n",
    "out_dict = {}\n",
    "for window in windows:\n",
    "    out_dict[str(window)] = modeling.windowed_base_detection(b_m, window, feature_read_list[0], b_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a843ca6a-a1a6-4b41-a421-19bc127f9744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(0, 7)': [0, 1, 3, 4, 5, 6],\n",
       " '(7, 14)': [7, 8, 9, 10, 11, 12, 13],\n",
       " '(14, 21)': [14, 15, 16, 17, 19, 20],\n",
       " '(21, 28)': [22, 23, 24, 25, 26, 27],\n",
       " '(35, 42)': [35, 36, 37, 39, 40, 41],\n",
       " '(49, 56)': [49, 51, 52, 53, 54, 55],\n",
       " '(56, 63)': [56, 58, 59, 60, 61, 62],\n",
       " '(70, 77)': [70, 71, 72, 73, 74, 75, 76],\n",
       " '(77, 84)': [77, 78, 80, 81, 82, 83],\n",
       " '(84, 91)': [84, 85, 86, 87, 89, 90],\n",
       " '(91, 98)': [91, 92, 93, 94, 95, 96],\n",
       " '(105, 112)': [105, 107, 108, 109, 110],\n",
       " '(112, 119)': [113, 114, 116, 117, 118],\n",
       " '(119, 126)': [119, 120, 121, 122, 123, 124]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4a996-7629-4238-b7a9-8f282401c534",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### The following dont work because the data is too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860c1de-f649-46c4-8517-7092bc16ded9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GC_json_dir='/media/sebastian/Slepnir/xenofind_datasets/0604_testing_datasets/GC_center_null_dataset/xna_find/json_files/'\n",
    "GC_singlet_dir = '/media/sebastian/Slepnir/xenofind_datasets/0604_testing_datasets/GC_center_null_dataset/xna_find/parquet_superdirectory/'\n",
    "json_to_singlets(GC_json_dir, GC_singlet_dir, 1)\n",
    "GC_feature_list = get_features_from_singlets(GC_singlet_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17841b-2ed1-4f4b-b740-191ec97a1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classified = []\n",
    "\n",
    "# loop through the first ten strands\n",
    "for j in range(len(GC_feature_list)):\n",
    "    \n",
    "    # get the strand data\n",
    "    test_consensus = GC_feature_list[j]\n",
    "    \n",
    "    #---- ------ ---- ------ WINDOW MODELING ---- ------ ----- ------ ----- #\n",
    "    # batch the bases into windows of size seven\n",
    "    base_windows= [test_consensus[i:int(i+window_size*2+1)] for i in range(0, len(test_consensus), int(window_size*2+1))]\n",
    "    \n",
    "    # set up lists for window classes and features\n",
    "    window_classes = []\n",
    "    window_features = []\n",
    "    \n",
    "    # for each window minus the potentially inconsistently sized one,\n",
    "    for base_window in base_windows[:-1]:\n",
    "        \n",
    "        # generate an empty list for the window's 1d features\n",
    "        window_sub_features = []\n",
    "        \n",
    "        # check if there's an XNA, append a 1 to the classes if so.\n",
    "        if len(base_window[base_window['XNA_PRESENT'] > 0]) > 0:\n",
    "            window_classes.append(1)\n",
    "        else:\n",
    "            window_classes.append(0)\n",
    "            \n",
    "        # loop through each base features, and extend the features to the 1d feature array\n",
    "        for base in base_window.drop(columns=['XNA_PRESENT']).values:\n",
    "            window_sub_features.extend(base)\n",
    "            \n",
    "        # append the window's 1d features to the list.\n",
    "        window_features.append(window_sub_features)\n",
    "    \n",
    "    # Create a scale of the window features + convert to tensors for features and labels\n",
    "    scale = scaler.fit_transform(window_features)\n",
    "    strand_features = torch.tensor(pca.transform(scale)).type(torch.float).to(device)\n",
    "    strand_labels = torch.tensor(np.asarray(window_classes)).type(torch.LongTensor).to(device)\n",
    "    \n",
    "    # pass window features to models for strands\n",
    "    strand_logits = loaded_window_model.model(strand_features)\n",
    "\n",
    "    # Get the predictions for the model\n",
    "    strand_predictions = torch.softmax(strand_logits, dim=1).argmax(dim=1)\n",
    "    \n",
    "    #convert the predictions to a list\n",
    "    predictions = strand_predictions.tolist()\n",
    "    \n",
    "    # get the true window predictions as a list\n",
    "    trues = strand_labels.tolist()\n",
    "    \n",
    "    # convert the predictions to a series\n",
    "    pred_series=pd.Series(predictions)\n",
    "    \n",
    "    # get the lsit of windows predicted\n",
    "    idd_windows = list(zip(np.asarray(pred_series[pred_series> 0].index.tolist())*(window_size*2+1), (np.asarray(pred_series[pred_series> 0].index.tolist())+1)*(window_size*2+1)))\n",
    "    \n",
    "    # ------ ------ ------ WINDOW BASE MODELING ------------------------#\n",
    "    print(\"Sequence {}:\".format(j+1))\n",
    "    \n",
    "    # generate an empty base list\n",
    "    base_list = []\n",
    "    \n",
    "    # for each window in the predicted windows:\n",
    "    for window in idd_windows:\n",
    "        \n",
    "        # get the base region from the strand as defined in the window\n",
    "        xna_region = test_consensus[window[0]:window[1]]\n",
    "        \n",
    "        # get the features and classes\n",
    "        xna_region_features = xna_region.loc[:, xna_region.columns != 'XNA_PRESENT']\n",
    "        xna_region_classes = xna_region['XNA_PRESENT']\n",
    "        \n",
    "        # conform those to the base scaler\n",
    "        base_scale = base_scaler.fit_transform(xna_region_features)\n",
    "        \n",
    "        # get the features and labels as tensors\n",
    "        region_features = torch.tensor(b_pca.transform(base_scale)).type(torch.float).to(device)\n",
    "        region_labels = torch.tensor(np.asarray(xna_region_classes)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        # generate the logits with the loaded base_model\n",
    "        region_logits = loaded_base_model.model(region_features)\n",
    "        \n",
    "        # get the predicted base classes\n",
    "        xna_predictions = torch.softmax(region_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "        # get the list of predictions\n",
    "        xna = xna_predictions.tolist()\n",
    "        \n",
    "        # get the true bases\n",
    "        true_xna = region_labels.tolist()\n",
    "        \n",
    "        # get the series of predicted bases\n",
    "        pred_xna_series = pd.Series(xna)\n",
    "        \n",
    "        # extend the identified base list with all bases identified as XNA by the model\n",
    "        base_list.extend((np.asarray(pred_xna_series[pred_xna_series >0].index.tolist()) + window[0]).tolist())\n",
    "        \n",
    "    # report the identified regions and bases\n",
    "    print(\"Identified Regions: {}\".format(idd_windows))\n",
    "    print(\"Identified Bases: {}\".format(base_list))\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522308ce-08ca-42cc-ab90-d7f68db658d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### P/Z, B/Sn Dataset\n",
    "Expected Results: Classification of PZ at position 90, Noise for B/Sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef72edb7-eec7-4da5-852b-0260e8fbb269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                    |  0.0%                0/2   est_time:0:00:00.047016 | 0:00:00.023508\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m PZBSN_json_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/media/sebastian/Slepnir/xenofind_datasets/0604_testing_datasets/GC_center_null_dataset/xna_find/json_files/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m PZBSN_singlet_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/media/sebastian/Slepnir/xenofind_datasets/0604_testing_datasets/GC_center_null_dataset/xna_find/parquet_superdirectory/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mjson_to_singlets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPZBSN_json_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPZBSN_singlet_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSinglets Made\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m, in \u001b[0;36mjson_to_singlets\u001b[0;34m(json_dir, singlet_consensus_dir, batch_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# setup a multiprocessing pool matching the batch size\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(batch_size) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# run feature extraction on the json files in the pool using yoink_features\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     feature_read_list\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoink_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_batch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Get the time estimate and duration\u001b[39;00m\n\u001b[1;32m     50\u001b[0m time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/xna_seq/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PZBSN_json_dir='/media/sebastian/Slepnir/xenofind_datasets/0604_testing_datasets/GC_center_null_dataset/xna_find/json_files/'\n",
    "PZBSN_singlet_dir = '/media/sebastian/Slepnir/xenofind_datasets/0604_testing_datasets/GC_center_null_dataset/xna_find/parquet_superdirectory/'\n",
    "json_to_singlets(PZBSN_json_dir, PZBSN_singlet_dir, 1)\n",
    "print('Singlets Made')\n",
    "print()\n",
    "PZBSN_feature_list = get_features_from_singlets(PZBSN_singlet_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738773a2-b237-47bd-a1aa-58773374d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classified = []\n",
    "\n",
    "# loop through the first ten strands\n",
    "for j in range(len(PZBSN_feature_list)):\n",
    "    \n",
    "    # get the strand data\n",
    "    test_consensus = PZBSN_feature_list[j]\n",
    "    \n",
    "    #---- ------ ---- ------ WINDOW MODELING ---- ------ ----- ------ ----- #\n",
    "    # batch the bases into windows of size seven\n",
    "    base_windows= [test_consensus[i:int(i+window_size*2+1)] for i in range(0, len(test_consensus), int(window_size*2+1))]\n",
    "    \n",
    "    # set up lists for window classes and features\n",
    "    window_classes = []\n",
    "    window_features = []\n",
    "    \n",
    "    # for each window minus the potentially inconsistently sized one,\n",
    "    for base_window in base_windows[:-1]:\n",
    "        \n",
    "        # generate an empty list for the window's 1d features\n",
    "        window_sub_features = []\n",
    "        \n",
    "        # check if there's an XNA, append a 1 to the classes if so.\n",
    "        if len(base_window[base_window['XNA_PRESENT'] > 0]) > 0:\n",
    "            window_classes.append(1)\n",
    "        else:\n",
    "            window_classes.append(0)\n",
    "            \n",
    "        # loop through each base features, and extend the features to the 1d feature array\n",
    "        for base in base_window.drop(columns=['XNA_PRESENT']).values:\n",
    "            window_sub_features.extend(base)\n",
    "            \n",
    "        # append the window's 1d features to the list.\n",
    "        window_features.append(window_sub_features)\n",
    "    \n",
    "    # Create a scale of the window features + convert to tensors for features and labels\n",
    "    scale = scaler.fit_transform(window_features)\n",
    "    strand_features = torch.tensor(pca.transform(scale)).type(torch.float).to(device)\n",
    "    strand_labels = torch.tensor(np.asarray(window_classes)).type(torch.LongTensor).to(device)\n",
    "    \n",
    "    # pass window features to models for strands\n",
    "    strand_logits = loaded_window_model.model(strand_features)\n",
    "\n",
    "    # Get the predictions for the model\n",
    "    strand_predictions = torch.softmax(strand_logits, dim=1).argmax(dim=1)\n",
    "    \n",
    "    #convert the predictions to a list\n",
    "    predictions = strand_predictions.tolist()\n",
    "    \n",
    "    # get the true window predictions as a list\n",
    "    trues = strand_labels.tolist()\n",
    "    \n",
    "    # convert the predictions to a series\n",
    "    pred_series=pd.Series(predictions)\n",
    "    \n",
    "    # get the lsit of windows predicted\n",
    "    idd_windows = list(zip(np.asarray(pred_series[pred_series> 0].index.tolist())*(window_size*2+1), (np.asarray(pred_series[pred_series> 0].index.tolist())+1)*(window_size*2+1)))\n",
    "    \n",
    "    # ------ ------ ------ WINDOW BASE MODELING ------------------------#\n",
    "    print(\"Sequence {}:\".format(j+1))\n",
    "    \n",
    "    # generate an empty base list\n",
    "    base_list = []\n",
    "    \n",
    "    # for each window in the predicted windows:\n",
    "    for window in idd_windows:\n",
    "        \n",
    "        # get the base region from the strand as defined in the window\n",
    "        xna_region = test_consensus[window[0]:window[1]]\n",
    "        \n",
    "        # get the features and classes\n",
    "        xna_region_features = xna_region.loc[:, xna_region.columns != 'XNA_PRESENT']\n",
    "        xna_region_classes = xna_region['XNA_PRESENT']\n",
    "        \n",
    "        # conform those to the base scaler\n",
    "        base_scale = base_scaler.fit_transform(xna_region_features)\n",
    "        \n",
    "        # get the features and labels as tensors\n",
    "        region_features = torch.tensor(b_pca.transform(base_scale)).type(torch.float).to(device)\n",
    "        region_labels = torch.tensor(np.asarray(xna_region_classes)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        # generate the logits with the base_model\n",
    "        region_logits = loaded_base_model.model(region_features)\n",
    "        \n",
    "        # get the predicted base classes\n",
    "        xna_predictions = torch.softmax(region_logits, dim=1).argmax(dim=1)\n",
    "        \n",
    "        # get the list of predictions\n",
    "        xna = xna_predictions.tolist()\n",
    "        \n",
    "        # get the true bases\n",
    "        true_xna = region_labels.tolist()\n",
    "        \n",
    "        # get the series of predicted bases\n",
    "        pred_xna_series = pd.Series(xna)\n",
    "        \n",
    "        # extend the identified base list with all bases identified as XNA by the model\n",
    "        base_list.extend((np.asarray(pred_xna_series[pred_xna_series >0].index.tolist()) + window[0]).tolist())\n",
    "        \n",
    "    # report the identified regions and bases\n",
    "    print(\"Identified Regions: {}\".format(idd_windows))\n",
    "    print(\"Identified Bases: {}\".format(base_list))\n",
    "\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xna_seq",
   "language": "python",
   "name": "xna_seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
