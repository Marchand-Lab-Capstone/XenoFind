{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c042783-f617-4792-bb45-d05695ab0b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import remora\n",
    "import sys\n",
    "sys.path.append('..//')\n",
    "import shannon_entropies as sp\n",
    "import pod5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51823817-5561-4d2f-8f33-259505d45790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pod5_data(p5_path):\n",
    "    data_list = []\n",
    "    with pod5.Reader(p5_path) as pod5_file:\n",
    "        for read in pod5_file.reads():\n",
    "            seq_id = read.read_id\n",
    "            signal = read.signal_pa\n",
    "            freq = read.run_info.sample_rate\n",
    "            time_step = 1/freq\n",
    "            time = np.full((signal.shape)[0], time_step)\n",
    "            time = np.cumsum(time)\n",
    "            data_dict = {'seq_id': seq_id,\n",
    "                         'signal': signal,\n",
    "                         'time': time}\n",
    "            data_list.append(data_dict)\n",
    "           \n",
    "    return data_list\n",
    "\n",
    "#https://pod5-file-format.readthedocs.io/en/latest/reference/api/pod5.reader.html#pod5.reader.ReadRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3f1436-dbcb-4ded-958a-beef56ea2e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_signal(stride_length, raw_moves, signal):\n",
    "    stride_moves = []\n",
    "    for i in range(len(raw_moves)):\n",
    "        if raw_moves[i]==0:\n",
    "            for j in range(stride_length):\n",
    "                stride_moves.append(raw_moves[i])\n",
    "        else:\n",
    "            stride_moves.append(1)\n",
    "    stride_moves = np.array(stride_moves)\n",
    "    stride_indicies = np.where(stride_moves == 1)[0]\n",
    "    obs_signals = []\n",
    "    for i in range(len(stride_indicies)-1):\n",
    "        beg_index = stride_indicies[i]\n",
    "        end_dex = stride_indicies[i+1]\n",
    "        obs_signal = signal[beg_index:end_dex]\n",
    "        obs_signals.append(obs_signal)\n",
    "    \n",
    "    return obs_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6f2db3-4172-4cf0-81a8-e47b0348f0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align_observation_ops(cig, sig, ref):\n",
    "    observation_dict_list = []\n",
    "    observation_indexer = 0\n",
    "    for observation in cig:\n",
    "        ob_type = observation[0]\n",
    "        ob_len = observation[1]\n",
    "        for i in range(ob_len):\n",
    "            try:\n",
    "                observation_dict = {'operation':ob_type,\n",
    "                                    'signal':sig[i+observation_indexer]}\n",
    "            except:\n",
    "                observation_dict = {'operation':ob_type,\n",
    "                                    'signal':None}\n",
    "            observation_dict_list.append(observation_dict)\n",
    "        observation_indexer += ob_len\n",
    "    obs_df = pd.DataFrame(observation_dict_list).shift(ref)\n",
    "    valued_operations = obs_df[(obs_df['operation'] != 4) |( obs_df['operation'] != 4)].reset_index(drop='true')\n",
    "\n",
    "    return valued_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c279ed-3c12-43a1-b15c-2d54a0d3f17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shift_to_alignment(ops, sigs, seq, quals, ref_len):\n",
    "    base_position = 0\n",
    "    base_keys = np.arange(ref_len).tolist()\n",
    "    base_dict = {key:[] for key in base_keys}\n",
    "    qual_dict =  {key:[] for key in base_keys}\n",
    "    sig_dict = {key:[] for key in base_keys}\n",
    "    for op in ops:\n",
    "        if (op == str(0.0)):\n",
    "            base_dict[base_position].append(seq[base_position])\n",
    "            qual_dict[base_position].append(qual[base_position])\n",
    "            sig_dict[base_position].append(sigs[base_position])\n",
    "            base_position += 1\n",
    "        elif (op == str(1.0)):\n",
    "            base_dict[base_position].append(\"+\")\n",
    "            qual_dict[base_position].append(seq[base_position])\n",
    "            sig_dict[base_position].append(sigs[base_position])\n",
    "        elif(op == str(2.0)):\n",
    "            seq.insert(base_position, \"-\")\n",
    "            sigs.insert(base_position, \"D\")\n",
    "            quals.insert(base_position, None)\n",
    "            base_dict[base_position].append(\"-\")\n",
    "            qual_dict[base_position].append(None)\n",
    "            sig_dict[base_position].append(None)\n",
    "            base_position += 1\n",
    "        elif(op == 'nan'):\n",
    "            # Nan is shift\n",
    "            seq.insert(base_position, \"N\")\n",
    "            quals.insert(base_position, None)\n",
    "            sigs.insert(base_position, \"S\")\n",
    "            base_dict[base_position].append(\"\")\n",
    "            qual_dict[base_position].append(None)\n",
    "            sig_dict[base_position].append(None)\n",
    "            base_position += 1\n",
    "            \n",
    "    return [base_dict, qual_dict, sig_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a454d06-5773-4d0c-9364-a417d9090054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the paths\n",
    "bam_path = \"../../../data/large_working_directory/rough_consensus_output/large_align.bam\"\n",
    "pod5_path = \"../../../data/large_working_directory/merged_pod5/merged.pod5\"\n",
    "ref_fasta = \"../../../data/reads_large/230725_PZ_lib_v4_r10/fasta/good.fa\"\n",
    "\n",
    "# Use the shannon entropy methods to load the bam\n",
    "loaded_bam = sp.load_in_data(bam_path)\n",
    "\n",
    "# covnert the sequence id to strings\n",
    "loaded_bam['seq_id'] = loaded_bam['seq_id'].astype(str)\n",
    "\n",
    "#Load the consensus reference fasta using shannon entropy methods\n",
    "cons_df = sp.consensus_formatter(ref_fasta)\n",
    "\n",
    "# Load the pod5 read data using load_pod5_data\n",
    "dl = load_pod5_data(pod5_path)\n",
    "\n",
    "# Convert to dataframe\n",
    "dl_df = pd.DataFrame(dl)\n",
    "\n",
    "# Convert the sequence ID to a string\n",
    "dl_df['seq_id'] = dl_df['seq_id'].astype(str)\n",
    "\n",
    "# merge the reads_dataframe and the bam dataframe by the sequence ID\n",
    "merged_data_df = pd.merge(loaded_bam, dl_df, on='seq_id', how='left')\n",
    "\n",
    "# to save memory, initialize the variables\n",
    "loaded_bam, dl_df = None, None\n",
    "\n",
    "\n",
    "# Loop through this section for each read in the data, in other words: Turn into its own method that is then\n",
    "# Applied to the merged_data_df, or even the merged_data_df thats merged with the consnensus fasta------------\n",
    "# Extract the stride, raw moves, signal, of the first read\n",
    "index = 1\n",
    "stride = merged_data_df.iloc[index]['moves'][0]\n",
    "raw = merged_data_df.iloc[index]['moves'][1:]\n",
    "sig = merged_data_df.iloc[index]['signal']\n",
    "\n",
    "# split the signal into discrete parts by the moves\n",
    "split_sig = split_signal(stride, raw, sig)\n",
    "\n",
    "# Get cigar string and reference position\n",
    "cig_seq = merged_data_df['cigar'][index]\n",
    "ref_pos = merged_data_df['ref'][index]\n",
    "\n",
    "# Use the signal, cigar, and reference to get the valued operations and signals\n",
    "val_ops = align_observation_ops(cig_seq, sig, ref_pos)\n",
    "\n",
    "# get the operation series as a string:\n",
    "operations = val_ops['operation'].apply(str)\n",
    "\n",
    "# get the quality scores for the current read\n",
    "qual = merged_data_df['quality'][index]\n",
    "\n",
    "# get the signal as the list\n",
    "signals = list(val_ops['signal'])\n",
    "\n",
    "# get the read sequence as a list\n",
    "seq_list = list(merged_data_df['sequence'][index])\n",
    "\n",
    "#get the reference sequence id\n",
    "ref_seq_id = merged_data_df['ref_name'][index]\n",
    "\n",
    "# get the reference sequence length\n",
    "ref_length = len(cons_df[cons_df['id'] == ref_seq_id]['seq'].values[0])\n",
    "\n",
    "# Get the alignment shift:\n",
    "\n",
    "alignment_shift = shift_to_alignment(operations, signals, seq_list, qual, ref_length)\n",
    "# ------- This should probably use .apply(), but there may be memory issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xna_seq",
   "language": "python",
   "name": "xna_seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
