{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c042783-f617-4792-bb45-d05695ab0b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import remora\n",
    "import sys\n",
    "sys.path.append('..//')\n",
    "import shannon_entropies as sp\n",
    "import pod5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import line_profiler as lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51823817-5561-4d2f-8f33-259505d45790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pod5_data(p5_path):\n",
    "    \n",
    "    # For some godforsaken reason, pod5 somehow consumes upwards of 6 GiB of memory when this runs, \n",
    "    # and it DOES NOT DISSAPEAR. ESLIT'rkjasvkajs;flksarejva;lkrvj\n",
    "    data_list = []\n",
    "    with pod5.Reader(p5_path) as pod5_file:\n",
    "        for read in pod5_file.reads():\n",
    "            seq_id = read.read_id\n",
    "            signal = read.signal_pa\n",
    "            freq = read.run_info.sample_rate\n",
    "            data_dict = {'seq_id': str(seq_id),\n",
    "                         'signal': signal,\n",
    "                         'freq': freq}\n",
    "            data_list.append(data_dict)\n",
    "            \n",
    "    return data_list\n",
    "\n",
    "#https://pod5-file-format.readthedocs.io/en/latest/reference/api/pod5.reader.html#pod5.reader.ReadRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3f1436-dbcb-4ded-958a-beef56ea2e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_signal(stride_length, raw_moves, signal):\n",
    "    stride_moves = []\n",
    "    for i in range(len(raw_moves)):\n",
    "        if raw_moves[i]==0:\n",
    "            for j in range(stride_length):\n",
    "                stride_moves.append(raw_moves[i])\n",
    "        else:\n",
    "            stride_moves.append(1)\n",
    "    stride_moves = np.array(stride_moves)\n",
    "    stride_indicies = np.where(stride_moves == 1)[0]\n",
    "    obs_signals = []\n",
    "    for i in range(len(stride_indicies)-1):\n",
    "        beg_index = stride_indicies[i]\n",
    "        end_dex = stride_indicies[i+1]\n",
    "        obs_signal = signal[beg_index:end_dex]\n",
    "        obs_signals.append(obs_signal)\n",
    "    \n",
    "    return obs_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6f2db3-4172-4cf0-81a8-e47b0348f0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align_observation_ops(cig, sig, ref):\n",
    "    observation_dict_list = []\n",
    "    observation_indexer = 0\n",
    "    for observation in cig:\n",
    "        ob_type = observation[0]\n",
    "        ob_len = observation[1]\n",
    "        for i in range(ob_len):\n",
    "            try:\n",
    "                observation_dict = {'operation':ob_type,\n",
    "                                    'signal':sig[i+observation_indexer]}\n",
    "            except:\n",
    "                observation_dict = {'operation':ob_type,\n",
    "                                    'signal':None}\n",
    "            observation_dict_list.append(observation_dict)\n",
    "        observation_indexer += ob_len\n",
    "    obs_df = pd.DataFrame(observation_dict_list).shift(ref)\n",
    "    valued_operations = obs_df[(obs_df['operation'] != 4) |( obs_df['operation'] != 4)].reset_index(drop='true')\n",
    "\n",
    "    return valued_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74c279ed-3c12-43a1-b15c-2d54a0d3f17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shift_to_alignment(ops, sigs, seq, quals, ref_len):\n",
    "    base_position = 0\n",
    "    base_keys = np.arange(ref_len).tolist()\n",
    "    base_dict = {key:[] for key in base_keys}\n",
    "    qual_dict =  {key:[] for key in base_keys}\n",
    "    sig_dict = {key:[] for key in base_keys}\n",
    "    for op in ops:\n",
    "        if (op == str(0.0)):\n",
    "            base_dict[base_position].append(seq[base_position])\n",
    "            qual_dict[base_position].append(qual[base_position])\n",
    "            sig_dict[base_position].append(sigs[base_position])\n",
    "            base_position += 1\n",
    "        elif (op == str(1.0)):\n",
    "            base_dict[base_position].append(\"+\")\n",
    "            qual_dict[base_position].append(seq[base_position])\n",
    "            sig_dict[base_position].append(sigs[base_position])\n",
    "        elif(op == str(2.0)):\n",
    "            seq.insert(base_position, \"-\")\n",
    "            sigs.insert(base_position, \"D\")\n",
    "            quals.insert(base_position, None)\n",
    "            base_dict[base_position].append(\"-\")\n",
    "            qual_dict[base_position].append(None)\n",
    "            sig_dict[base_position].append(None)\n",
    "            base_position += 1\n",
    "        elif(op == 'nan'):\n",
    "            # Nan is shift\n",
    "            seq.insert(base_position, \"N\")\n",
    "            quals.insert(base_position, None)\n",
    "            sigs.insert(base_position, \"S\")\n",
    "            base_dict[base_position].append(\"\")\n",
    "            qual_dict[base_position].append(None)\n",
    "            sig_dict[base_position].append(None)\n",
    "            base_position += 1\n",
    "            \n",
    "    return [base_dict, qual_dict, sig_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "074124ec-ee41-4b40-8d57-fbc4b8ea89f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_bam_reads_by_id(bam_list_dict, read_list_dict, consensus_list_dict):\n",
    "        \n",
    "    # this code can be made more time efficient and memory-chunking but that's not important rn\n",
    "    bld = pd.DataFrame(bam_list_dict)\n",
    "    rld = pd.DataFrame(read_list_dict)\n",
    "    cld = pd.DataFrame(consensus_list_dict)\n",
    "    \n",
    "    merged_data_df = pd.merge(bld, rld, on='seq_id', how='left')\n",
    "    \n",
    "    for i in range(len(cld)):\n",
    "        #merged_data_df.at[]\n",
    "        indexes = merged_data_df[merged_data_df['ref_name'] == cld['id'][i]].index\n",
    "        merged_data_df.loc[indexes,'ref_seq'] = cld['seq'][i]\n",
    "    \n",
    "    \n",
    "    data_dict = merged_data_df.to_dict('records')\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a454d06-5773-4d0c-9364-a417d9090054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1671784\n"
     ]
    }
   ],
   "source": [
    "# Load the paths\n",
    "bam_path = \"../../../data/large_working_directory/rough_consensus_output/large_align.bam\"\n",
    "pod5_path = \"../../../data/large_working_directory/merged_pod5/merged.pod5\"\n",
    "ref_fasta = \"../../../data/reads_large/230725_PZ_lib_v4_r10/fasta/good.fa\"\n",
    "\n",
    "# Use the shannon entropy methods to load the bam\n",
    "loaded_bam = sp.load_in_data(bam_path)\n",
    "\n",
    "print(sys.getsizeof(loaded_bam))\n",
    "\n",
    "#Load the consensus reference fasta using shannon entropy methods\n",
    "consens = sp.consensus_formatter(ref_fasta)\n",
    "\n",
    "# Load the pod5 read data using load_pod5_data\n",
    "dl = load_pod5_data(pod5_path)\n",
    "\n",
    "# Merge the data\n",
    "merged_list_dict = merge_bam_reads_by_id(loaded_bam, dl, consens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1954bcad-1b11-4859-a82c-c8961e18ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through this section for each read in the data, in other words: Turn into its own method that is then\n",
    "# Applied to the merged_data_df, or even the merged_data_df thats merged with the consnensus fasta------------\n",
    "# Extract the stride, raw moves, signal, of the first read\n",
    "index = 1\n",
    "stride = merged_data_df.iloc[index]['moves'][0]\n",
    "raw = merged_data_df.iloc[index]['moves'][1:]\n",
    "sig = merged_data_df.iloc[index]['signal']\n",
    "\n",
    "# split the signal into discrete parts by the moves\n",
    "split_sig = split_signal(stride, raw, sig)\n",
    "\n",
    "# Get cigar string and reference position\n",
    "cig_seq = merged_data_df['cigar'][index]\n",
    "ref_pos = merged_data_df['ref'][index]\n",
    "\n",
    "# Use the signal, cigar, and reference to get the valued operations and signals\n",
    "val_ops = align_observation_ops(cig_seq, sig, ref_pos)\n",
    "\n",
    "# get the operation series as a string:\n",
    "operations = val_ops['operation'].apply(str)\n",
    "\n",
    "# get the quality scores for the current read\n",
    "qual = merged_data_df['quality'][index]\n",
    "\n",
    "# get the signal as the list\n",
    "signals = list(val_ops['signal'])\n",
    "\n",
    "# get the read sequence as a list\n",
    "seq_list = list(merged_data_df['sequence'][index])\n",
    "\n",
    "#get the reference sequence id\n",
    "ref_seq_id = merged_data_df['ref_name'][index]\n",
    "\n",
    "# get the reference sequence length\n",
    "ref_length = len(cons_df[cons_df['id'] == ref_seq_id]['seq'].values[0])\n",
    "\n",
    "# Get the alignment shift:\n",
    "\n",
    "alignment_shift = shift_to_alignment(operations, signals, seq_list, qual, ref_length)\n",
    "# ------- This should probably use .apply(), but there may be memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44d6de18-7b9f-4969-bbfb-94bf7387d3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.639848 s\n",
      "File: /tmp/ipykernel_29956/237270870.py\n",
      "Function: merge_bam_reads_by_id at line 2\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     2                                           def merge_bam_reads_by_id(bam_list_dict, read_list_dict, consensus_list_dict):\n",
      "     3                                               \n",
      "     4         1   44547050.0    4e+07      7.0      read_ids = [str(x['seq_id']) for x in bam_list_dict][:10]\n",
      "     5                                               \n",
      "     6         1       1031.0   1031.0      0.0      merged_bam_reads = []\n",
      "     7        11      11536.0   1048.7      0.0      for i in range(len(read_ids)):\n",
      "     8                                                   #print(\"{}/{}     \".format(i, len(read_ids)), end='\\r')\n",
      "     9        10       7081.0    708.1      0.0          read = read_ids[i]\n",
      "    10        10  374431873.0    4e+07     58.5          bam_read_dict = list(d for d in bam_list_dict if d[\"seq_id\"] == read)[0]\n",
      "    11        10  220796911.0    2e+07     34.5          raw_read_ls = list(d for d in read_list_dict if d[\"seq_id\"] == read)\n",
      "    12        10      16490.0   1649.0      0.0          if len(raw_read_ls) > 0:\n",
      "    13        10       6527.0    652.7      0.0              raw_read_dict = raw_read_ls[0]\n",
      "    14                                           \n",
      "    15        10       9454.0    945.4      0.0              bam_read_dict['signal'] = raw_read_dict['signal']\n",
      "    16        10       5387.0    538.7      0.0              bam_read_dict['freq'] = raw_read_dict['freq']\n",
      "    17        10      14793.0   1479.3      0.0              merged_bam_reads.append(bam_read_dict)\n",
      "    18                                                   \n",
      "    19                                               \n",
      "    20                                           \n",
      "    21         1        128.0    128.0      0.0      return merged_bam_reads\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler = lprof.LineProfiler()\n",
    "def merge_bam_reads_by_id(bam_list_dict, read_list_dict, consensus_list_dict):\n",
    "        \n",
    "    read_ids = [str(x['seq_id']) for x in bam_list_dict][:10]\n",
    "    \n",
    "    merged_bam_reads = []\n",
    "    for i in range(len(read_ids)):\n",
    "        #print(\"{}/{}     \".format(i, len(read_ids)), end='\\r')\n",
    "        read = read_ids[i]\n",
    "        bam_read_dict = list(d for d in bam_list_dict if d[\"seq_id\"] == read)[0]\n",
    "        raw_read_ls = list(d for d in read_list_dict if d[\"seq_id\"] == read)\n",
    "        if len(raw_read_ls) > 0:\n",
    "            raw_read_dict = raw_read_ls[0]\n",
    "\n",
    "            bam_read_dict['signal'] = raw_read_dict['signal']\n",
    "            bam_read_dict['freq'] = raw_read_dict['freq']\n",
    "            merged_bam_reads.append(bam_read_dict)\n",
    "        \n",
    "    \n",
    "\n",
    "    return merged_bam_reads\n",
    "\n",
    "profiled_func = profiler(merge_bam_reads_by_id)\n",
    "profiled_func(loaded_bam, dl, consens) \n",
    "profiler.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a75121-6c0c-43c5-9092-9e17ccfc2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663b200-1c80-41ad-a26d-4eb7a0c74a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0d742c-1816-4cfe-a6f8-63fca2d33f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6868089114"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(merged_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f8fde-b5c6-4a7b-b4e4-1f01e9dcb481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data_df['reference_seq'] = merged_data_df['ref_name'].apply(lambda x: get_ref_by_id(x, cons_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b09c14aa-a5eb-41b2-8fa4-2da46c14f090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pool=ACGTAACTTGGTTTGTTCCCTGAA-AGTCAGCT+CGAGGAGGTTCACTGGGTAGTAAG-TTCCAGGA+XPOS[P:66]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_df['ref_name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "391e8df5-2666-4ad1-9bb3-fee77adef4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_df['ref_name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec3d928c-8d17-4db9-bfe6-50703de4c783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_df['ref_name'][0] in cons_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e95d4e1-aa34-4577-a3f7-48724b008345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment_info(, ):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xna_seq",
   "language": "python",
   "name": "xna_seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
